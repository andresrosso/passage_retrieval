{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 5103)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import QAData\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import PassageRetrieval as pr\n",
    "from json2html import *\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "import pylab as plt\n",
    "import nlp_utils\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from json_utils import JSONConnector\n",
    "from QAData import DataSetFactory\n",
    "import models\n",
    "from passrtv_models import PassageRetrievalModel\n",
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "from keras.layers import Convolution1D, Convolution2D\n",
    "from keras.layers import Input, Embedding, merge, Flatten, SimpleRNN\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalMaxPooling2D, Activation, Input, Dense, merge, Dropout, LSTM\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Convolution2D, GlobalMaxPooling2D, Activation, Input, Dense, merge, Dropout\n",
    "from keras.layers import Flatten, SimpleRNN\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import Callback\n",
    "from itertools import groupby\n",
    "import sys\n",
    "import pickle\n",
    "import nlp_utils\n",
    "import numpy as np\n",
    "import threading\n",
    "import models as models\n",
    "from models import threadsafe_generator\n",
    "from scipy import spatial\n",
    "import nltk\n",
    "from random import shuffle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "  \"expriment_id\" : \"keras_convnet_$runid\",\n",
    "  \"dataset_partitions\" : [\"train\",\"validate\",\"test\"],\n",
    "  \"dataset\": \"TrecDataSet\",\n",
    "  \"ground_truth_file\": \"/home/aerossom/passage-retrieval/experiments/gold-jakana-test.rank\",\n",
    "  \"model\" : \"KerasConvNetModel_8\",\n",
    "  \"modeldes\" : \"Convolutional NN with 1d input tensor cosine sim input matrix element wise multiplied by salience matrix\",\n",
    "  \"out_folder\": \"/home/aerossom/passage-retrieval/experiments/\",\n",
    "  \"working_folder\": \"/home/aerossom/passage-retrieval/experiments/working_files/\",\n",
    "  \"trec_eval_path\" : \"/home/aerossom/trec_eval.9.0/trec_eval\",\n",
    "  \"out_rank_file\" : \"keras_convnet_matrixsim_$runid.rank\",\n",
    "  \"word2vect_path\" : \"/home/aerossom/datasets/word2vect/GoogleNews-vectors-negative300.bin\",\n",
    "  \"preprocess_steps\" : [],\n",
    "  \"method_params\" : {\n",
    "                      \"optimizer\": \"rmsprop\",\n",
    "                      \"loss\":\"mean_squared_error\",\n",
    "                      \"monitor\": \"val_loss\",\n",
    "                      \"verbose\" : 1,\n",
    "                      \"positive_rate\": 0.5,\n",
    "            \t\t      \"epochs\": 500,\n",
    "            \t\t      \"batch_size\": 256,\n",
    "            \t\t      \"validation_size\" : 64,\n",
    "            \t\t      \"max_words\" : 40,\n",
    "            \t\t      \"patience\": 50,\n",
    "                      \"convolution_2d\" : {\n",
    "                        \"nb_filter\": 64,\n",
    "                        \"nb_row\": 3,\n",
    "                        \"nb_col\": 3,\n",
    "                        \"subsample\": 1,\n",
    "                        \"border_mode\" : \"valid\",\n",
    "                        \"activation\" : \"relu\"\n",
    "                      },\n",
    "                      \"activation_2nd_Layer\" : \"relu\",\n",
    "                      \"dense_4th_Layer\" : 30,\n",
    "                      \"dropout\" : 0.1,\n",
    "                      \"dense_6th_layer\" : 1,\n",
    "                      \"end_layer_activation\" : \"sigmoid\"\n",
    "\t\t    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2v_path = '/home/aerossom/datasets/word2vect/GoogleNews-vectors-negative300.bin'\n",
    "w2v_util = nlp_utils.Word2vectUtils(w2v_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ds = DataSetFactory.loadDataSet('WikiQADataSet')\n",
    "#ds = DataSetFactory.loadDataSet('TrecDataSet_TrainAll')\n",
    "#ds = DataSetFactory.loadDataSet('WikiQADataSet')\n",
    "\n",
    "qa_pair = {}\n",
    "qa_pair['train'] = ds.build_qa_pairs(ds.questions['train'])\n",
    "qa_pair['validate'] = ds.build_qa_pairs(ds.questions['validate'])\n",
    "qa_pair['test'] = ds.build_qa_pairs(ds.questions['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def avg_precision(y_true, y_pred):\n",
    "    zipped = zip(y_true, y_pred)\n",
    "    zipped.sort(key=lambda x:x[1],reverse=True)\n",
    "    np_y_true, np_y_pred = zip(*zipped)\n",
    "    k_list = [i for i in range(len(np_y_true)) if int(np_y_true[i])==1]\n",
    "    score = 0.\n",
    "    r = np.sum(np_y_true).astype(np.int64)\n",
    "    for k in k_list:\n",
    "        Yk = np.sum(np_y_true[:k+1])\n",
    "        score += Yk/float(k+1)\n",
    "    if r==0:\n",
    "        return 0\n",
    "    score/=(r)\n",
    "    return score\n",
    "\n",
    "\"\"\"\n",
    "https://en.wikipedia.org/wiki/Mean_reciprocal_rank\n",
    "\"\"\"\n",
    "def reciprocal_rank(y_true, y_pred):\n",
    "    zipped = zip(y_true, y_pred)\n",
    "    zipped.sort(key=lambda x:x[1],reverse=True)\n",
    "    count_r = 1.0\n",
    "    rr_score = 0.0\n",
    "    for y_t,y_p in zipped:\n",
    "        if(y_t!=1):\n",
    "            count_r += 1\n",
    "        else:\n",
    "            rr_score = 1.0/count_r\n",
    "            break\n",
    "    if count_r-1==len(y_true):\n",
    "        rr_score = 0.0\n",
    "    return rr_score\n",
    "\n",
    "class MAPCallback(Callback):\n",
    "    \n",
    "    def __init__(self, validation_data, max_words, proc_funct, filepath, min_delta=0, patience=50, verbose=1, save_best_only=True, save_weights_only=True, period=1):\n",
    "        super(MAPCallback, self).__init__()\n",
    "        self.val_ds = validation_data\n",
    "        self.max_words = max_words\n",
    "        self.proc_fuction = proc_funct\n",
    "        self.map_score = []\n",
    "        self.mrr_score = []\n",
    "        self.min_delta = min_delta\n",
    "        #maximize the map\n",
    "        self.monitor_op = np.greater\n",
    "        self.patience = patience\n",
    "        self.period = period\n",
    "        self.verbose = verbose\n",
    "        self.save_best_only = save_best_only\n",
    "        self.save_weights_only = save_weights_only\n",
    "        self.epochs_since_last_save = 0\n",
    "        self.filepath = filepath\n",
    "        self.min_delta *= -1\n",
    "        self.stopped_epoch = 0\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.wait = 0  # Allow instances to be re-used\n",
    "        self.best = np.Inf if self.monitor_op == np.less else -np.Inf\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current_map, current_mrr = self.calculate_map_mrr()\n",
    "        self.save_model(epoch, logs, current_map)\n",
    "        logging.info(\"MAP evaluation - epoch: {:d} - score: {:.6f}\".format(epoch, current_map))\n",
    "        logging.info(\"MRR evaluation - epoch: {:d} - score: {:.6f}\".format(epoch, current_mrr))\n",
    "        if current_map is None:\n",
    "            warnings.warn('MAP Early stopping requires %s available!' %\n",
    "                          (self.monitor), RuntimeWarning)\n",
    "\n",
    "        if self.monitor_op(current_map - self.min_delta, self.best):\n",
    "            self.best = current_map\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "            self.wait += 1\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0 and self.verbose > 0:\n",
    "        #    print('Epoch %05d: MAP early stopping' % (self.stopped_epoch))\n",
    "            logging.info(\"MAP early stopping Epoch {:d} evaluation - MAP: {:.6f} \".format(self.stopped_epoch,self.best))\n",
    "    \n",
    "    def save_model(self, epoch, logs, cmap):\n",
    "        logs = logs or {}\n",
    "        self.epochs_since_last_save += 1\n",
    "        if self.epochs_since_last_save >= self.period:\n",
    "            self.epochs_since_last_save = 0\n",
    "            filepath = self.filepath.format(epoch=epoch, **logs)\n",
    "            if self.save_best_only:\n",
    "                current = cmap\n",
    "                if current is None:\n",
    "                    warnings.warn('Can save best model only with %s available, '\n",
    "                                  'skipping.' % (' MAP '), RuntimeWarning)\n",
    "                else:\n",
    "                    if self.monitor_op(current, self.best):\n",
    "                        if self.verbose > 0:\n",
    "                            print('Epoch %05d: %s improved from %0.5f to %0.5f,'\n",
    "                                  ' saving model to %s'\n",
    "                                  % (epoch, ' MAP ', self.best,\n",
    "                                     current, filepath))\n",
    "                        self.best = current\n",
    "                        if self.save_weights_only:\n",
    "                            self.model.save_weights(filepath, overwrite=True)\n",
    "                        else:\n",
    "                            self.model.save(filepath, overwrite=True)\n",
    "                    else:\n",
    "                        if self.verbose > 0:\n",
    "                            print('Epoch %05d: %s did not improve' %\n",
    "                                  (epoch, ' MAP '))\n",
    "            else:\n",
    "                if self.verbose > 0:\n",
    "                    print('Epoch %05d: saving model to %s' % (epoch, filepath))\n",
    "                if self.save_weights_only:\n",
    "                    self.model.save_weights(filepath, overwrite=True)\n",
    "                else:\n",
    "                    self.model.save(filepath, overwrite=True)\n",
    "\n",
    "    def calculate_map_mrr(self):\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        avg_p = []\n",
    "        rr_list = []\n",
    "        num_groups = 0\n",
    "        for key, group in groupby(self.val_ds, lambda x: x.qi):\n",
    "            samples = []\n",
    "            is_any_true = False\n",
    "            for q_g in group:\n",
    "                samples.append(q_g)\n",
    "                if q_g.l == 1:\n",
    "                    is_any_true = True\n",
    "            #Just take the 1/3 of the dataset randomly\n",
    "            if random.uniform(0, 10) > 8:\n",
    "                is_any_true = False\n",
    "            if is_any_true:\n",
    "                x, y_true = self.proc_fuction(samples,max_terms=self.max_words)\n",
    "                y_pred = self.model.predict_proba(x, verbose=0)\n",
    "                avg_p_score = avg_precision(y_true, y_pred)\n",
    "                avg_p.append( avg_p_score )\n",
    "                rr_score = reciprocal_rank(y_true, y_pred)\n",
    "                rr_list.append( rr_score )\n",
    "                #print y_true\n",
    "                #print y_pred\n",
    "                #print 'avg_prec = ', avg_p_score, ', rr = ', rr_score\n",
    "                num_groups += 1\n",
    "        cmap_score = sum(avg_p)/num_groups\n",
    "        cmrr_score = sum(rr_list)/num_groups\n",
    "        self.map_score.append(cmap_score)\n",
    "        self.mrr_score.append(cmrr_score)\n",
    "        #print 'map = ', cmap_score, ', mrr = ', cmrr_score\n",
    "        return cmap_score, cmrr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Convolutional NN with 1d input tensor cosine sim input matrix element wise multiplied by salience matrix\n",
    "\"\"\"\n",
    "class KerasConvNetModel_8(models.PassageRetrievalModel):\n",
    "\n",
    "    def __init__(self,init_params):\n",
    "        super(KerasConvNetModel_8, self).__init__('KerasConvNetModel_8', init_params['runid'])\n",
    "        self.w2vutil = init_params['w2v']\n",
    "        self.w2v = self.w2vutil.getWord2VectModel()\n",
    "        self.params = init_params['params']\n",
    "        self.max_words = self.params['method_params']['max_words']\n",
    "        self.positive_rate = self.params['method_params']['positive_rate']\n",
    "        self.prep_step = [ str(step) for step in init_params['params']['preprocess_steps'] ]\n",
    "\n",
    "    \n",
    "\n",
    "    def getSalienceScore(self, qv, av, maxterms=40):\n",
    "        score = 0\n",
    "        imp_postag = set(['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'NN', 'NNS', 'NNP', 'NNPS', 'JJ'])\n",
    "        #imp_postag = set(['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ', 'WDT', 'WP', 'WP', 'WRB', 'NN', 'NNS', 'NNP', 'NNPS', 'MD'])\n",
    "        #imp_postag = set(['WRB','VB', 'VBD', 'VBG', 'VBN', 'VBP','VBZ', 'WDT', 'WP', 'WRB', 'NN', 'NNS', 'NNP', 'NNPS', 'MD'])\n",
    "        pq = nltk.pos_tag(qv)\n",
    "        pa = nltk.pos_tag(av)\n",
    "        out_m = np.zeros( (maxterms, maxterms) )\n",
    "        if len(pq)>maxterms:\n",
    "            pq = pq[0:maxterms]\n",
    "        if len(pa)>maxterms:\n",
    "            pa = pa[0:maxterms]\n",
    "        wq_m = np.zeros((maxterms,maxterms))\n",
    "        wa_m = np.zeros((maxterms,maxterms))\n",
    "\n",
    "        pq_l = [len(set([qt[1]]).intersection(imp_postag))+1 for qt in pq]\n",
    "        pa_l = [len(set([at[1]]).intersection(imp_postag))+1 for at in pa]\n",
    "\n",
    "        wq_m[0:len(pa_l) , 0:len(pq_l)]=pq_l\n",
    "        wa_m[0:len(pq_l) , 0:len(pa_l)]=pa_l\n",
    "\n",
    "        out_m = (wq_m.T + wa_m)/4\n",
    "        return out_m[0:maxterms,0:maxterms]\n",
    "\n",
    "    def buildCosineSimMatrix(self, questions_answer_pairs, max_terms=40):\n",
    "        #Construct Question Answer Matrix Pairs\n",
    "        x = []\n",
    "        y = []\n",
    "        for pair in questions_answer_pairs:\n",
    "            #Question Processing\n",
    "            q_list = nlp_utils.data_preprocess(pair.q,self.prep_step)\n",
    "            q_vect = self.w2vutil.transform2Word2Vect(q_list)\n",
    "            #Answer processing\n",
    "            a_list = nlp_utils.data_preprocess(pair.a,self.prep_step)\n",
    "            a_vect = self.w2vutil.transform2Word2Vect(a_list)\n",
    "            #Get salience score\n",
    "            #sal_matrix = self.getSalienceScore(q_list,a_list,max_terms)\n",
    "            #Get cosine distance\n",
    "            #distance = np.absolute( spatial.distance.cdist(q_vect[0:max_terms], a_vect[0:max_terms], 'cosine') )\n",
    "            ''' with that param the MAP and Loss are  highly correlated\n",
    "                and the improvement in MAP is very fast, but in test the results are almost equal\n",
    "                cos_matrix = 1 - (1/(1+np.exp(-distance*3)))\n",
    "                it changes a bit with\n",
    "                cos_matrix = 1 - (1/(1+np.exp(-distance*2)))\n",
    "\n",
    "            distance = spatial.distance.cdist(q_vect[0:max_terms], a_vect[0:max_terms],\n",
    "              lambda u, v: (np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v)))\n",
    "                    if (np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))) >= 0\n",
    "                    else -1.0*(np.dot(u, v) / (np.linalg.norm(u) * np.linalg.norm(v))) )\n",
    "                    '''\n",
    "            distance = spatial.distance.cdist(q_vect[0:max_terms], a_vect[0:max_terms], 'cosine')\n",
    "            #cos_matrix = 1 - distance\n",
    "            cos_matrix = 1 - distance/2\n",
    "            shape_cos_matrix = cos_matrix.shape\n",
    "            cos_matrix = np.pad(cos_matrix, ((0,max_terms-shape_cos_matrix[0]),(0,max_terms-shape_cos_matrix[1])), mode='constant')\n",
    "            if np.isnan(cos_matrix).any():\n",
    "                print 'ERROR IS NAN: ',pair\n",
    "            #x.append( np.multiply(cos_matrix,sal_matrix).flatten() )\n",
    "            x.append( cos_matrix.flatten() )\n",
    "            y.append( pair.l )\n",
    "        #print 'x shape: ', np.array(x).shape\n",
    "        return np.array(x), np.array(y)\n",
    "\n",
    "    def load_model(self):\n",
    "        self.model = Sequential()\n",
    "        mp = self.params['method_params']\n",
    "        self.model.add(Dense(128, input_dim=1600, activation='relu'))\n",
    "        self.model.add(Dense(32))\n",
    "        self.model.add(Dropout(0.1))\n",
    "        #self.model.add(Dense(mp['dense_6th_layer']))\n",
    "        self.model.add(Dense(1, activation='sigmoid'))\n",
    "        return self.model\n",
    "    \n",
    "    @threadsafe_generator\n",
    "    def generateXYBatches(self, samples_xy, num_samples, positive_rate=0.5):\n",
    "        num_pos_samples = int(num_samples*(positive_rate))\n",
    "        positiveSamples = [ q for q in samples_xy if q[1]==1 ]\n",
    "        negativeSamples = [ q for q in samples_xy if q[1]==0 ]\n",
    "        print 'samples = ',num_samples, ', len+:', len(positiveSamples), ', len-:',len(negativeSamples)\n",
    "        samples_xy = random.sample(positiveSamples, num_pos_samples)+random.sample(negativeSamples, num_samples-num_pos_samples)\n",
    "        shuffle(samples_xy)\n",
    "        while 1:\n",
    "            x,y = zip(*samples_xy)\n",
    "            #'x_shape: ',np.array(x).shape\n",
    "            #x, y = self.buildCosineSimMatrix(samples,max_terms=self.max_words)\n",
    "            yield ( np.array(x), np.array(y) )\n",
    "\n",
    "    def train(self, ds, qa_pair):\n",
    "        self.model = self.load_model()\n",
    "        self.best_params=self.params['working_folder']+self.params['expriment_id'].replace('$runid',self.runid)+\"_best.hdf5\"\n",
    "        #if want to load the best weights in other training\n",
    "        #self.model.load_weights(self.best_params)\n",
    "        #MAP CallBack\n",
    "        map_callback = MAPCallback(qa_pair['validate'], self.max_words, self.buildCosineSimMatrix, self.best_params)\n",
    "        # checkpoints\n",
    "        #output the model weights each time an improvement is observed during training\n",
    "        #checkpoint = ModelCheckpoint(self.best_params, monitor=self.params['method_params']['monitor'], verbose=self.params['method_params']['verbose'], save_best_only=True, mode='auto')\n",
    "        #stops if the model is not learning at any point\n",
    "        #earlyStopping= EarlyStopping(monitor=self.params['method_params']['monitor'], patience=self.params['method_params']['patience'], verbose=self.params['method_params']['verbose'], mode='auto')\n",
    "        train_qxa, train_l = k_model.buildCosineSimMatrix(qa_pair['train'][0:100], max_terms=40)\n",
    "        val_qxa, val_l   = k_model.buildCosineSimMatrix(qa_pair['validate'][0:100], max_terms=40)\n",
    "        \n",
    "        epochs_number = self.params['method_params']['epochs']\n",
    "        batch_size = self.params['method_params']['batch_size']\n",
    "        validation_size = self.params['method_params']['validation_size']\n",
    "\n",
    "        self.model.compile(loss='mean_squared_error',\n",
    "                      optimizer='rmsprop',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        history = self.model.fit_generator(\n",
    "                    self.generateXYBatches( zip(train_qxa,train_l ), 2, positive_rate=self.positive_rate),\n",
    "                    samples_per_epoch=batch_size,\n",
    "                    validation_data=self.generateXYBatches( zip(val_qxa,val_l), 2, positive_rate=self.positive_rate),\n",
    "                    nb_val_samples=2,\n",
    "                    nb_epoch=epochs_number,\n",
    "                    callbacks=[map_callback]\n",
    "                    #callbacks=[checkpoint, earlyStopping, map_callback]\n",
    "                    )\n",
    "        \n",
    "        #Add MAP and MRR to history\n",
    "        history.history['map'] = map_callback.map_score\n",
    "        history.history['mrr'] = map_callback.mrr_score\n",
    "        #Save history object in pickel\n",
    "        self.save_history( self.best_params.replace('_best.hdf5','_history.pkl'), history )\n",
    "        return history\n",
    "    \n",
    "    def save_history(self,out_file, history):\n",
    "        with open(out_file, 'wb') as output:\n",
    "            pickle.dump(history.history, output, pickle.HIGHEST_PROTOCOL)\n",
    "        \"\"\"\n",
    "        To Open \n",
    "            with open('in_file.pkl', 'rb') as input:\n",
    "                history = pickle.load(input)\n",
    "        \"\"\"\n",
    "\n",
    "    def test(self, ds, qa_pairs):\n",
    "        #reload best weights\n",
    "        self.model.load_weights(self.best_params)\n",
    "        #Construct Test dataset\n",
    "        test_qxa, test_l = self.buildCosineSimMatrix(qa_pairs, max_terms=self.max_words)\n",
    "        predictions = self.model.predict(np.array(test_qxa))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_params = {\"w2v\": w2v_util, \"runid\":'test_run',  \"params\":params }\n",
    "k_model = KerasConvNetModel_8(model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "dense_109 (Dense)                (None, 128)           204928      dense_input_40[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "dense_110 (Dense)                (None, 32)            4128        dense_109[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dropout_38 (Dropout)             (None, 32)            0           dense_110[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_111 (Dense)                (None, 1)             33          dropout_38[0][0]                 \n",
      "====================================================================================================\n",
      "Total params: 209089\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "k_model.load_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples = Epoch 1/500 \n",
      "2 , len+: 5 , len-: 95\n",
      "248/256 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9919samples =  2 , len+: 5 , len-: 95\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 0 - score: 0.334875\n",
      "INFO:root:MRR evaluation - epoch: 0 - score: 0.338902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00000:  MAP  improved from -inf to 0.33487, saving model to /home/aerossom/passage-retrieval/experiments/working_files/keras_convnet_test_run_best.hdf5\n",
      "256/256 [==============================] - 1s - loss: 0.0054 - acc: 0.9922 - val_loss: 0.2302 - val_acc: 0.5000\n",
      "Epoch 2/500\n",
      "252/256 [============================>.] - ETA: 0s - loss: 1.7314e-07 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 1 - score: 0.337447\n",
      "INFO:root:MRR evaluation - epoch: 1 - score: 0.340792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00001:  MAP  improved from 0.33487 to 0.33745, saving model to /home/aerossom/passage-retrieval/experiments/working_files/keras_convnet_test_run_best.hdf5\n",
      "256/256 [==============================] - 1s - loss: 1.7044e-07 - acc: 1.0000 - val_loss: 0.3611 - val_acc: 0.5000\n",
      "Epoch 3/500\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.0303e-09 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 2 - score: 0.338953\n",
      "INFO:root:MRR evaluation - epoch: 2 - score: 0.340283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00002:  MAP  improved from 0.33745 to 0.33895, saving model to /home/aerossom/passage-retrieval/experiments/working_files/keras_convnet_test_run_best.hdf5\n",
      "256/256 [==============================] - 1s - loss: 1.0241e-09 - acc: 1.0000 - val_loss: 0.3315 - val_acc: 0.5000\n",
      "Epoch 4/500\n",
      "250/256 [============================>.] - ETA: 0s - loss: 1.2615e-10 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 3 - score: 0.357427\n",
      "INFO:root:MRR evaluation - epoch: 3 - score: 0.361283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00003:  MAP  improved from 0.33895 to 0.35743, saving model to /home/aerossom/passage-retrieval/experiments/working_files/keras_convnet_test_run_best.hdf5\n",
      "256/256 [==============================] - 1s - loss: 1.2324e-10 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.5000\n",
      "Epoch 5/500\n",
      "250/256 [============================>.] - ETA: 0s - loss: 6.3599e-11 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 4 - score: 0.330691\n",
      "INFO:root:MRR evaluation - epoch: 4 - score: 0.335541\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00004:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 6.2157e-11 - acc: 1.0000 - val_loss: 0.2813 - val_acc: 0.5000\n",
      "Epoch 6/500\n",
      "248/256 [============================>.] - ETA: 0s - loss: 2.4215e-11 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 5 - score: 0.364728\n",
      "INFO:root:MRR evaluation - epoch: 5 - score: 0.369627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00005:  MAP  improved from 0.35743 to 0.36473, saving model to /home/aerossom/passage-retrieval/experiments/working_files/keras_convnet_test_run_best.hdf5\n",
      "256/256 [==============================] - 1s - loss: 2.3566e-11 - acc: 1.0000 - val_loss: 0.2752 - val_acc: 0.5000\n",
      "Epoch 7/500\n",
      "250/256 [============================>.] - ETA: 0s - loss: 1.3174e-11 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 6 - score: 0.351340\n",
      "INFO:root:MRR evaluation - epoch: 6 - score: 0.352214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00006:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 1.2907e-11 - acc: 1.0000 - val_loss: 0.2756 - val_acc: 0.5000\n",
      "Epoch 8/500\n",
      "250/256 [============================>.] - ETA: 0s - loss: 1.2458e-11 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 7 - score: 0.347089\n",
      "INFO:root:MRR evaluation - epoch: 7 - score: 0.348964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00007:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 1.2386e-11 - acc: 1.0000 - val_loss: 0.2744 - val_acc: 0.5000\n",
      "Epoch 9/500\n",
      "252/256 [============================>.] - ETA: 0s - loss: 5.3280e-11 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 8 - score: 0.344844\n",
      "INFO:root:MRR evaluation - epoch: 8 - score: 0.349951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00008:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 5.2459e-11 - acc: 1.0000 - val_loss: 0.2567 - val_acc: 0.5000\n",
      "Epoch 10/500\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.1527e-11 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 9 - score: 0.328503\n",
      "INFO:root:MRR evaluation - epoch: 9 - score: 0.331665\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00009:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 1.1553e-11 - acc: 1.0000 - val_loss: 0.2602 - val_acc: 0.5000\n",
      "Epoch 11/500\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.0365e-10 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 10 - score: 0.340754\n",
      "INFO:root:MRR evaluation - epoch: 10 - score: 0.345196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00010:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 1.0285e-10 - acc: 1.0000 - val_loss: 0.3286 - val_acc: 0.5000\n",
      "Epoch 12/500\n",
      "252/256 [============================>.] - ETA: 0s - loss: 1.3778e-11 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 11 - score: 0.333223\n",
      "INFO:root:MRR evaluation - epoch: 11 - score: 0.338536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00011:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 1.3578e-11 - acc: 1.0000 - val_loss: 0.3253 - val_acc: 0.5000\n",
      "Epoch 13/500\n",
      "252/256 [============================>.] - ETA: 0s - loss: 6.3360e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 12 - score: 0.366882\n",
      "INFO:root:MRR evaluation - epoch: 12 - score: 0.371283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00012:  MAP  improved from 0.36473 to 0.36688, saving model to /home/aerossom/passage-retrieval/experiments/working_files/keras_convnet_test_run_best.hdf5\n",
      "256/256 [==============================] - 1s - loss: 6.2515e-12 - acc: 1.0000 - val_loss: 0.3226 - val_acc: 0.5000\n",
      "Epoch 14/500\n",
      "250/256 [============================>.] - ETA: 0s - loss: 1.2470e-11 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 13 - score: 0.354638\n",
      "INFO:root:MRR evaluation - epoch: 13 - score: 0.359691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00013:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 1.2233e-11 - acc: 1.0000 - val_loss: 0.3185 - val_acc: 0.5000\n",
      "Epoch 15/500\n",
      "252/256 [============================>.] - ETA: 0s - loss: 2.9421e-11 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 14 - score: 0.351692\n",
      "INFO:root:MRR evaluation - epoch: 14 - score: 0.356272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00014:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 2.8968e-11 - acc: 1.0000 - val_loss: 0.3051 - val_acc: 0.5000\n",
      "Epoch 16/500\n",
      "248/256 [============================>.] - ETA: 0s - loss: 8.2248e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 15 - score: 0.347412\n",
      "INFO:root:MRR evaluation - epoch: 15 - score: 0.351791\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00015:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 8.0353e-12 - acc: 1.0000 - val_loss: 0.3031 - val_acc: 0.5000\n",
      "Epoch 17/500\n",
      "252/256 [============================>.] - ETA: 0s - loss: 3.9537e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 16 - score: 0.355044\n",
      "INFO:root:MRR evaluation - epoch: 16 - score: 0.360249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00016:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 3.9037e-12 - acc: 1.0000 - val_loss: 0.3025 - val_acc: 0.5000\n",
      "Epoch 18/500\n",
      "250/256 [============================>.] - ETA: 0s - loss: 5.7653e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 17 - score: 0.333769\n",
      "INFO:root:MRR evaluation - epoch: 17 - score: 0.336406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00017:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 5.6625e-12 - acc: 1.0000 - val_loss: 0.3026 - val_acc: 0.5000\n",
      "Epoch 19/500\n",
      "250/256 [============================>.] - ETA: 0s - loss: 4.9641e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 18 - score: 0.336314\n",
      "INFO:root:MRR evaluation - epoch: 18 - score: 0.340543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00018:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 5.6327e-12 - acc: 1.0000 - val_loss: 0.3010 - val_acc: 0.5000\n",
      "Epoch 20/500\n",
      "250/256 [============================>.] - ETA: 0s - loss: 3.2598e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 19 - score: 0.343027\n",
      "INFO:root:MRR evaluation - epoch: 19 - score: 0.346639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00019:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 3.1983e-12 - acc: 1.0000 - val_loss: 0.3003 - val_acc: 0.5000\n",
      "Epoch 21/500\n",
      "252/256 [============================>.] - ETA: 0s - loss: 4.2551e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 20 - score: 0.333613\n",
      "INFO:root:MRR evaluation - epoch: 20 - score: 0.334553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00020:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 4.1905e-12 - acc: 1.0000 - val_loss: 0.2985 - val_acc: 0.5000\n",
      "Epoch 22/500\n",
      "254/256 [============================>.] - ETA: 0s - loss: 7.1024e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 21 - score: 0.348365\n",
      "INFO:root:MRR evaluation - epoch: 21 - score: 0.350874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00021:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 7.0478e-12 - acc: 1.0000 - val_loss: 0.2955 - val_acc: 0.5000\n",
      "Epoch 23/500\n",
      "254/256 [============================>.] - ETA: 0s - loss: 9.0664e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 22 - score: 0.339380\n",
      "INFO:root:MRR evaluation - epoch: 22 - score: 0.344178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00022:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 9.0276e-12 - acc: 1.0000 - val_loss: 0.2946 - val_acc: 0.5000\n",
      "Epoch 24/500\n",
      "252/256 [============================>.] - ETA: 0s - loss: 2.7663e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 23 - score: 0.355409\n",
      "INFO:root:MRR evaluation - epoch: 23 - score: 0.359900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00023:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 2.7276e-12 - acc: 1.0000 - val_loss: 0.2935 - val_acc: 0.5000\n",
      "Epoch 25/500\n",
      "248/256 [============================>.] - ETA: 0s - loss: 3.4715e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 24 - score: 0.338149\n",
      "INFO:root:MRR evaluation - epoch: 24 - score: 0.340045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00024:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 3.3751e-12 - acc: 1.0000 - val_loss: 0.2922 - val_acc: 0.5000\n",
      "Epoch 26/500\n",
      "254/256 [============================>.] - ETA: 0s - loss: 5.8606e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 25 - score: 0.357439\n",
      "INFO:root:MRR evaluation - epoch: 25 - score: 0.356947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00025:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 5.8151e-12 - acc: 1.0000 - val_loss: 0.2907 - val_acc: 0.5000\n",
      "Epoch 27/500\n",
      "254/256 [============================>.] - ETA: 0s - loss: 3.6551e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 26 - score: 0.333441\n",
      "INFO:root:MRR evaluation - epoch: 26 - score: 0.338125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00026:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 3.6297e-12 - acc: 1.0000 - val_loss: 0.2911 - val_acc: 0.5000\n",
      "Epoch 28/500\n",
      "250/256 [============================>.] - ETA: 0s - loss: 2.3769e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 27 - score: 0.358543\n",
      "INFO:root:MRR evaluation - epoch: 27 - score: 0.364122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00027:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 2.3394e-12 - acc: 1.0000 - val_loss: 0.2915 - val_acc: 0.5000\n",
      "Epoch 29/500\n",
      "250/256 [============================>.] - ETA: 0s - loss: 2.8979e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 28 - score: 0.339932\n",
      "INFO:root:MRR evaluation - epoch: 28 - score: 0.344049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00028:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 2.9159e-12 - acc: 1.0000 - val_loss: 0.2916 - val_acc: 0.5000\n",
      "Epoch 30/500\n",
      "250/256 [============================>.] - ETA: 0s - loss: 6.4048e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 29 - score: 0.355359\n",
      "INFO:root:MRR evaluation - epoch: 29 - score: 0.359366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00029:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 6.2604e-12 - acc: 1.0000 - val_loss: 0.2892 - val_acc: 0.5000\n",
      "Epoch 31/500\n",
      "254/256 [============================>.] - ETA: 0s - loss: 2.1240e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 30 - score: 0.342518\n",
      "INFO:root:MRR evaluation - epoch: 30 - score: 0.347410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00030:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 2.1235e-12 - acc: 1.0000 - val_loss: 0.2889 - val_acc: 0.5000\n",
      "Epoch 32/500\n",
      "250/256 [============================>.] - ETA: 0s - loss: 4.3632e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 31 - score: 0.341803\n",
      "INFO:root:MRR evaluation - epoch: 31 - score: 0.339793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00031:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 4.2956e-12 - acc: 1.0000 - val_loss: 0.2897 - val_acc: 0.5000\n",
      "Epoch 33/500\n",
      "254/256 [============================>.] - ETA: 0s - loss: 3.3023e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 32 - score: 0.352678\n",
      "INFO:root:MRR evaluation - epoch: 32 - score: 0.356788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00032:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 3.2779e-12 - acc: 1.0000 - val_loss: 0.2894 - val_acc: 0.5000\n",
      "Epoch 34/500\n",
      "250/256 [============================>.] - ETA: 0s - loss: 2.0418e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 33 - score: 0.333518\n",
      "INFO:root:MRR evaluation - epoch: 33 - score: 0.338090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00033:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 2.5583e-12 - acc: 1.0000 - val_loss: 0.2885 - val_acc: 0.5000\n",
      "Epoch 35/500\n",
      "250/256 [============================>.] - ETA: 0s - loss: 1.3215e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 34 - score: 0.348777\n",
      "INFO:root:MRR evaluation - epoch: 34 - score: 0.355063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00034:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 1.4742e-12 - acc: 1.0000 - val_loss: 0.2882 - val_acc: 0.5000\n",
      "Epoch 36/500\n",
      "254/256 [============================>.] - ETA: 0s - loss: 2.0849e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 35 - score: 0.349004\n",
      "INFO:root:MRR evaluation - epoch: 35 - score: 0.353764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00035:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 2.0706e-12 - acc: 1.0000 - val_loss: 0.2879 - val_acc: 0.5000\n",
      "Epoch 37/500\n",
      "254/256 [============================>.] - ETA: 0s - loss: 5.2672e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 36 - score: 0.332957\n",
      "INFO:root:MRR evaluation - epoch: 36 - score: 0.335315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00036:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 5.3539e-12 - acc: 1.0000 - val_loss: 0.2872 - val_acc: 0.5000\n",
      "Epoch 38/500\n",
      "248/256 [============================>.] - ETA: 0s - loss: 2.2150e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 37 - score: 0.330366\n",
      "INFO:root:MRR evaluation - epoch: 37 - score: 0.330547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00037:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 2.1565e-12 - acc: 1.0000 - val_loss: 0.2862 - val_acc: 0.5000\n",
      "Epoch 39/500\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.4211e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 38 - score: 0.336472\n",
      "INFO:root:MRR evaluation - epoch: 38 - score: 0.339545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00038:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 1.4168e-12 - acc: 1.0000 - val_loss: 0.2861 - val_acc: 0.5000\n",
      "Epoch 40/500\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.1949e-11 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 39 - score: 0.362826\n",
      "INFO:root:MRR evaluation - epoch: 39 - score: 0.366357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00039:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 1.1890e-11 - acc: 1.0000 - val_loss: 0.2806 - val_acc: 0.5000\n",
      "Epoch 41/500\n",
      "250/256 [============================>.] - ETA: 0s - loss: 1.3115e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 40 - score: 0.326747\n",
      "INFO:root:MRR evaluation - epoch: 40 - score: 0.328366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00040:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 1.2845e-12 - acc: 1.0000 - val_loss: 0.2805 - val_acc: 0.5000\n",
      "Epoch 42/500\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.6742e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 41 - score: 0.349565\n",
      "INFO:root:MRR evaluation - epoch: 41 - score: 0.353615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00041:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 1.6621e-12 - acc: 1.0000 - val_loss: 0.2799 - val_acc: 0.5000\n",
      "Epoch 43/500\n",
      "248/256 [============================>.] - ETA: 0s - loss: 1.3205e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 42 - score: 0.330941\n",
      "INFO:root:MRR evaluation - epoch: 42 - score: 0.333070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00042:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 1.2889e-12 - acc: 1.0000 - val_loss: 0.2798 - val_acc: 0.5000\n",
      "Epoch 44/500\n",
      "252/256 [============================>.] - ETA: 0s - loss: 6.4175e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 43 - score: 0.357058\n",
      "INFO:root:MRR evaluation - epoch: 43 - score: 0.361811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00043:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 6.3254e-12 - acc: 1.0000 - val_loss: 0.2776 - val_acc: 0.5000\n",
      "Epoch 45/500\n",
      "252/256 [============================>.] - ETA: 0s - loss: 1.7791e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 44 - score: 0.341424\n",
      "INFO:root:MRR evaluation - epoch: 44 - score: 0.343790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00044:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 1.7757e-12 - acc: 1.0000 - val_loss: 0.2771 - val_acc: 0.5000\n",
      "Epoch 46/500\n",
      "250/256 [============================>.] - ETA: 0s - loss: 1.9988e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 45 - score: 0.333368\n",
      "INFO:root:MRR evaluation - epoch: 45 - score: 0.335917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00045:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 1.9545e-12 - acc: 1.0000 - val_loss: 0.2767 - val_acc: 0.5000\n",
      "Epoch 47/500\n",
      "250/256 [============================>.] - ETA: 0s - loss: 3.8315e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 46 - score: 0.331484\n",
      "INFO:root:MRR evaluation - epoch: 46 - score: 0.335792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00046:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 3.7421e-12 - acc: 1.0000 - val_loss: 0.2770 - val_acc: 0.5000\n",
      "Epoch 48/500\n",
      "252/256 [============================>.] - ETA: 0s - loss: 1.8013e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 47 - score: 0.334918\n",
      "INFO:root:MRR evaluation - epoch: 47 - score: 0.338127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00047:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 1.7741e-12 - acc: 1.0000 - val_loss: 0.2763 - val_acc: 0.5000\n",
      "Epoch 49/500\n",
      "254/256 [============================>.] - ETA: 0s - loss: 1.5589e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 48 - score: 0.355613\n",
      "INFO:root:MRR evaluation - epoch: 48 - score: 0.358016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00048:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 1.5534e-12 - acc: 1.0000 - val_loss: 0.2766 - val_acc: 0.5000\n",
      "Epoch 50/500\n",
      "250/256 [============================>.] - ETA: 0s - loss: 3.1987e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 49 - score: 0.344457\n",
      "INFO:root:MRR evaluation - epoch: 49 - score: 0.348456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00049:  MAP  did not improve\n",
      "256/256 [==============================] - 1s - loss: 3.1336e-12 - acc: 1.0000 - val_loss: 0.2762 - val_acc: 0.5000\n",
      "Epoch 51/500\n",
      "250/256 [============================>.] - ETA: 0s - loss: 1.4338e-12 - acc: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP evaluation - epoch: 50 - score: 0.360346\n",
      "INFO:root:MRR evaluation - epoch: 50 - score: 0.364917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00050:  MAP  did not improve\n",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "256/256 [==============================] - 1s - loss: 1.4075e-12 - acc: 1.0000 - val_loss: 0.2762 - val_acc: 0.5000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:MAP early stopping Epoch 50 evaluation - MAP: 0.366882 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "history = k_model.train(ds, qa_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "keras.__version__\n",
    "from keras.layers import MaxPooling2D, Convolution2D, GlobalMaxPooling2D, GlobalAveragePooling2D, Activation, Input, Dense, merge, Dropout, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 s, sys: 0 ns, total: 11 s\n",
      "Wall time: 17.2 s\n"
     ]
    }
   ],
   "source": [
    "in_file = '/home/aerossom/passage-retrieval/experiments/working_files/keras_convnet_test_run_history.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the iron lady ; a biography of margaret thatcher by hugo young -lrb- farrar , straus & giroux -rrb-'"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_pair['train'][0].a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cosine_matrix = k_model.buildCosineSimMatrix(qa_pair['train'][0:1000],max_terms=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999990119566\n"
     ]
    }
   ],
   "source": [
    "print max(np.array(cosine_matrix[0]).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17, 17)"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_matrix[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pq = nltk.pos_tag(xq)\n",
    "pa = nltk.pos_tag(xa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('who', 'WP'), ('is', 'VBZ'), ('the', 'DT'), ('author', 'NN'), ('of', 'IN'), ('the', 'DT'), ('book', 'NN'), ('the', 'DT'), ('iron', 'NN'), ('lady', 'NN'), ('a', 'DT'), ('biography', 'NN'), ('of', 'IN'), ('margaret', 'NN'), ('thatcher', 'NN')] \n",
      "\n",
      "[('the', 'DT'), ('iron', 'NN'), ('lady', 'NN'), ('a', 'DT'), ('biography', 'NN'), ('of', 'IN'), ('margaret', 'NN'), ('thatcher', 'NN'), ('by', 'IN'), ('hugo', 'NN'), ('young', 'JJ'), ('lrb', 'NN'), ('farrar', 'NN'), ('straus', 'VBZ'), ('giroux', 'NN'), ('rrb', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "print pq,'\\n\\n', pa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=1)\n",
    "np.set_printoptions(threshold='nan')\n",
    "np.set_printoptions(suppress=True)\n",
    "#print test_qxa[0]\n",
    "print np.array_str(cosine_matrix[0][0][0], precision=2, suppress_small=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.384415864944\n"
     ]
    }
   ],
   "source": [
    "print str(spatial.distance.cosine(w2v_util.w2v_model['book'], w2v_util.w2v_model['biography']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(in_file, 'rb') as input:\n",
    "    history = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First predictions\n",
    "k_model = KerasConvNetModel_8(model_params)\n",
    "test_qxa, test_l = k_model.buildCosineSimMatrix(qa_pair['test'], max_terms=40)\n",
    "#train_qxa, train_l = k_model.buildCosineSimMatrix(qa_pair['train'], max_terms=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000004"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(test_qxa.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1517, 1, 40, 40)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_qxa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pair = zip(test_qxa, test_l )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1517, 1, 40, 40)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(zip(*pair)[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who is the author of the book , `` the iron lady : a biography of margaret thatcher '' ? the iron lady ; a biography of margaret thatcher by hugo young -lrb- farrar , straus & giroux -rrb-\n"
     ]
    }
   ],
   "source": [
    "print qa_pair['train'][0].q, qa_pair['train'][0].a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=1)\n",
    "np.set_printoptions(threshold='nan')\n",
    "np.set_printoptions(suppress=True)\n",
    "#print test_qxa[0]\n",
    "print np.array_str(train_qxa[0], precision=1, suppress_small=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87770495563745499"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial.distance.cosine(w2v_util.w2v_model['glacier'], w2v_util.w2v_model['oil'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "model = models.load_model('/home/aerossom/passage-retrieval/experiments/working_files/keras_convnet_1493417216_best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nlp_utils import avg_precision\n",
    "from nlp_utils import reciprocal_rank\n",
    "#Make the first preditions\n",
    "first_predictions = model.predict(np.array(test_qxa))\n",
    "rank_file_1 = 'experiments/rankfile_0.rank'\n",
    "idx_pred = 0\n",
    "rank_text = ''\n",
    "for key,group in groupby(qa_pair['test'], lambda x: x.qi):\n",
    "    for i, qp in enumerate(group):\n",
    "        rank_text += str(qp.qi) + ' 0 ' + str(qp.ai) + ' 0 ' + str(first_predictions[idx_pred][0]) + ' 0\\n'\n",
    "        idx_pred += 1\n",
    "with open(rank_file_1, 'wb') as text_file:\n",
    "    text_file.write(rank_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Trec\n",
    "!/home/aerossom/trec_eval.9.0/trec_eval -c /home/aerossom/passage-retrieval/experiments/gold-jakana-test2.rank \\\n",
    "experiments/rankfile_0.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runid                 \tall\t0\r\n",
      "num_q                 \tall\t237\r\n",
      "num_ret               \tall\t2341\r\n",
      "num_rel               \tall\t283\r\n",
      "num_rel_ret           \tall\t283\r\n",
      "map                   \tall\t0.6080\r\n",
      "gm_map                \tall\t0.4780\r\n",
      "Rprec                 \tall\t0.4409\r\n",
      "bpref                 \tall\t0.4342\r\n",
      "recip_rank            \tall\t0.6165\r\n",
      "iprec_at_recall_0.00  \tall\t0.6215\r\n",
      "iprec_at_recall_0.10  \tall\t0.6215\r\n",
      "iprec_at_recall_0.20  \tall\t0.6215\r\n",
      "iprec_at_recall_0.30  \tall\t0.6183\r\n",
      "iprec_at_recall_0.40  \tall\t0.6183\r\n",
      "iprec_at_recall_0.50  \tall\t0.6183\r\n",
      "iprec_at_recall_0.60  \tall\t0.6038\r\n",
      "iprec_at_recall_0.70  \tall\t0.6038\r\n",
      "iprec_at_recall_0.80  \tall\t0.5997\r\n",
      "iprec_at_recall_0.90  \tall\t0.5997\r\n",
      "iprec_at_recall_1.00  \tall\t0.5997\r\n",
      "P_5                   \tall\t0.1890\r\n",
      "P_10                  \tall\t0.1118\r\n",
      "P_15                  \tall\t0.0776\r\n",
      "P_20                  \tall\t0.0593\r\n",
      "P_30                  \tall\t0.0398\r\n",
      "P_100                 \tall\t0.0119\r\n",
      "P_200                 \tall\t0.0060\r\n",
      "P_500                 \tall\t0.0024\r\n",
      "P_1000                \tall\t0.0012\r\n"
     ]
    }
   ],
   "source": [
    "#WikiQA\n",
    "!/home/aerossom/trec_eval.9.0/trec_eval -c /home/aerossom/datasets/WikiQACorpus/WikiQA-test-filtered.ref \\\n",
    "experiments/rankfile_0.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  l= 1 map_1:  1.0  map_2:  1.0\n",
      "2  l= 0 map_1:  0  map_2:  0\n",
      "3  l= 1 map_1:  0.333333333333  map_2:  0.333333333333\n",
      "4  l= 1 map_1:  1.0  map_2:  1.0\n",
      "5  l= 4 map_1:  0.172442323758  map_2:  0.218181818182\n",
      "6  l= 0 map_1:  0  map_2:  0\n",
      "7  l= 0 map_1:  0  map_2:  0\n",
      "8  l= 0 map_1:  0  map_2:  0\n",
      "9  l= 0 map_1:  0  map_2:  0\n",
      "10  l= 1 map_1:  0.25  map_2:  0.166666666667\n",
      "11  l= 1 map_1:  1.0  map_2:  1.0\n",
      "12  l= 0 map_1:  0  map_2:  0\n",
      "13  l= 0 map_1:  0  map_2:  0\n",
      "14  l= 0 map_1:  0  map_2:  0\n",
      "15  l= 0 map_1:  0  map_2:  0\n",
      "16  l= 0 map_1:  0  map_2:  0\n",
      "17  l= 0 map_1:  0  map_2:  0\n",
      "18  l= 0 map_1:  0  map_2:  0\n",
      "19  l= 0 map_1:  0  map_2:  0\n",
      "20  l= 2 map_1:  0.642857142857  map_2:  0.642857142857\n",
      "21  l= 1 map_1:  1.0  map_2:  1.0\n",
      "22  l= 1 map_1:  0.333333333333  map_2:  0.333333333333\n",
      "23  l= 0 map_1:  0  map_2:  0\n",
      "24  l= 1 map_1:  0.5  map_2:  0.142857142857\n",
      "25  l= 0 map_1:  0  map_2:  0\n",
      "26  l= 0 map_1:  0  map_2:  0\n",
      "27  l= 2 map_1:  0.208333333333  map_2:  0.375\n",
      "28  l= 1 map_1:  0.5  map_2:  0.333333333333\n",
      "29  l= 1 map_1:  0.5  map_2:  0.5\n",
      "30  l= 2 map_1:  0.375  map_2:  0.416666666667\n",
      "31  l= 0 map_1:  0  map_2:  0\n",
      "32  l= 0 map_1:  0  map_2:  0\n",
      "33  l= 0 map_1:  0  map_2:  0\n",
      "34  l= 0 map_1:  0  map_2:  0\n",
      "35  l= 1 map_1:  0.333333333333  map_2:  0.333333333333\n",
      "36  l= 0 map_1:  0  map_2:  0\n",
      "37  l= 0 map_1:  0  map_2:  0\n",
      "38  l= 0 map_1:  0  map_2:  0\n",
      "39  l= 0 map_1:  0  map_2:  0\n",
      "40  l= 0 map_1:  0  map_2:  0\n",
      "41  l= 0 map_1:  0  map_2:  0\n",
      "42  l= 0 map_1:  0  map_2:  0\n",
      "43  l= 0 map_1:  0  map_2:  0\n",
      "44  l= 2 map_1:  1.0  map_2:  1.0\n",
      "45  l= 0 map_1:  0  map_2:  0\n",
      "46  l= 0 map_1:  0  map_2:  0\n",
      "47  l= 0 map_1:  0  map_2:  0\n",
      "48  l= 0 map_1:  0  map_2:  0\n",
      "49  l= 3 map_1:  1.0  map_2:  1.0\n",
      "50  l= 0 map_1:  0  map_2:  0\n",
      "51  l= 0 map_1:  0  map_2:  0\n",
      "52  l= 1 map_1:  0.5  map_2:  0.5\n",
      "53  l= 0 map_1:  0  map_2:  0\n",
      "54  l= 0 map_1:  0  map_2:  0\n",
      "55  l= 0 map_1:  0  map_2:  0\n",
      "56  l= 0 map_1:  0  map_2:  0\n",
      "57  l= 0 map_1:  0  map_2:  0\n",
      "58  l= 0 map_1:  0  map_2:  0\n",
      "59  l= 0 map_1:  0  map_2:  0\n",
      "60  l= 0 map_1:  0  map_2:  0\n",
      "61  l= 2 map_1:  0.75  map_2:  0.75\n",
      "62  l= 2 map_1:  0.183333333333  map_2:  0.174242424242\n",
      "63  l= 0 map_1:  0  map_2:  0\n",
      "64  l= 1 map_1:  1.0  map_2:  1.0\n",
      "65  l= 0 map_1:  0  map_2:  0\n",
      "66  l= 0 map_1:  0  map_2:  0\n",
      "67  l= 1 map_1:  0.333333333333  map_2:  0.333333333333\n",
      "68  l= 0 map_1:  0  map_2:  0\n",
      "69  l= 1 map_1:  1.0  map_2:  1.0\n",
      "70  l= 0 map_1:  0  map_2:  0\n",
      "71  l= 0 map_1:  0  map_2:  0\n",
      "72  l= 1 map_1:  1.0  map_2:  1.0\n",
      "73  l= 0 map_1:  0  map_2:  0\n",
      "74  l= 2 map_1:  0.583333333333  map_2:  0.583333333333\n",
      "75  l= 0 map_1:  0  map_2:  0\n",
      "76  l= 1 map_1:  1.0  map_2:  1.0\n",
      "77  l= 1 map_1:  0.333333333333  map_2:  0.25\n",
      "78  l= 0 map_1:  0  map_2:  0\n",
      "79  l= 0 map_1:  0  map_2:  0\n",
      "80  l= 1 map_1:  1.0  map_2:  1.0\n",
      "81  l= 1 map_1:  0.333333333333  map_2:  0.333333333333\n",
      "82  l= 0 map_1:  0  map_2:  0\n",
      "83  l= 1 map_1:  0.2  map_2:  0.333333333333\n",
      "84  l= 1 map_1:  1.0  map_2:  1.0\n",
      "85  l= 0 map_1:  0  map_2:  0\n",
      "86  l= 0 map_1:  0  map_2:  0\n",
      "87  l= 0 map_1:  0  map_2:  0\n",
      "88  l= 0 map_1:  0  map_2:  0\n",
      "89  l= 0 map_1:  0  map_2:  0\n",
      "90  l= 0 map_1:  0  map_2:  0\n",
      "91  l= 1 map_1:  1.0  map_2:  1.0\n",
      "92  l= 0 map_1:  0  map_2:  0\n",
      "93  l= 0 map_1:  0  map_2:  0\n",
      "94  l= 0 map_1:  0  map_2:  0\n",
      "95  l= 0 map_1:  0  map_2:  0\n",
      "96  l= 0 map_1:  0  map_2:  0\n",
      "97  l= 1 map_1:  0.5  map_2:  0.5\n",
      "98  l= 0 map_1:  0  map_2:  0\n",
      "99  l= 1 map_1:  1.0  map_2:  1.0\n",
      "100  l= 0 map_1:  0  map_2:  0\n",
      "101  l= 0 map_1:  0  map_2:  0\n",
      "102  l= 0 map_1:  0  map_2:  0\n",
      "103  l= 1 map_1:  1.0  map_2:  1.0\n",
      "104  l= 2 map_1:  0.583333333333  map_2:  0.5\n",
      "105  l= 0 map_1:  0  map_2:  0\n",
      "106  l= 0 map_1:  0  map_2:  0\n",
      "107  l= 0 map_1:  0  map_2:  0\n",
      "108  l= 0 map_1:  0  map_2:  0\n",
      "109  l= 0 map_1:  0  map_2:  0\n",
      "110  l= 0 map_1:  0  map_2:  0\n",
      "111  l= 0 map_1:  0  map_2:  0\n",
      "112  l= 0 map_1:  0  map_2:  0\n",
      "113  l= 0 map_1:  0  map_2:  0\n",
      "114  l= 0 map_1:  0  map_2:  0\n",
      "115  l= 0 map_1:  0  map_2:  0\n",
      "116  l= 0 map_1:  0  map_2:  0\n",
      "117  l= 0 map_1:  0  map_2:  0\n",
      "118  l= 0 map_1:  0  map_2:  0\n",
      "119  l= 1 map_1:  0.5  map_2:  0.5\n",
      "120  l= 1 map_1:  0.5  map_2:  0.333333333333\n",
      "121  l= 1 map_1:  0.5  map_2:  0.5\n",
      "122  l= 1 map_1:  0.333333333333  map_2:  0.25\n",
      "123  l= 0 map_1:  0  map_2:  0\n",
      "124  l= 1 map_1:  1.0  map_2:  1.0\n",
      "125  l= 0 map_1:  0  map_2:  0\n",
      "126  l= 0 map_1:  0  map_2:  0\n",
      "127  l= 1 map_1:  1.0  map_2:  1.0\n",
      "128  l= 1 map_1:  0.333333333333  map_2:  0.333333333333\n",
      "129  l= 1 map_1:  1.0  map_2:  1.0\n",
      "130  l= 0 map_1:  0  map_2:  0\n",
      "131  l= 0 map_1:  0  map_2:  0\n",
      "132  l= 0 map_1:  0  map_2:  0\n",
      "133  l= 1 map_1:  0.1  map_2:  0.1\n",
      "134  l= 1 map_1:  0.333333333333  map_2:  0.5\n",
      "135  l= 0 map_1:  0  map_2:  0\n",
      "136  l= 1 map_1:  1.0  map_2:  1.0\n",
      "137  l= 3 map_1:  1.0  map_2:  0.916666666667\n",
      "138  l= 1 map_1:  0.5  map_2:  0.5\n",
      "139  l= 0 map_1:  0  map_2:  0\n",
      "140  l= 1 map_1:  0.2  map_2:  0.333333333333\n",
      "141  l= 1 map_1:  1.0  map_2:  1.0\n",
      "142  l= 0 map_1:  0  map_2:  0\n",
      "143  l= 0 map_1:  0  map_2:  0\n",
      "144  l= 0 map_1:  0  map_2:  0\n",
      "145  l= 0 map_1:  0  map_2:  0\n",
      "146  l= 1 map_1:  0.125  map_2:  0.125\n",
      "147  l= 0 map_1:  0  map_2:  0\n",
      "148  l= 0 map_1:  0  map_2:  0\n",
      "149  l= 0 map_1:  0  map_2:  0\n",
      "150  l= 1 map_1:  1.0  map_2:  1.0\n",
      "151  l= 0 map_1:  0  map_2:  0\n",
      "152  l= 1 map_1:  0.2  map_2:  0.2\n",
      "153  l= 0 map_1:  0  map_2:  0\n",
      "154  l= 2 map_1:  0.75  map_2:  0.833333333333\n",
      "155  l= 0 map_1:  0  map_2:  0\n",
      "156  l= 1 map_1:  0.166666666667  map_2:  0.2\n",
      "157  l= 0 map_1:  0  map_2:  0\n",
      "158  l= 1 map_1:  1.0  map_2:  1.0\n",
      "159  l= 0 map_1:  0  map_2:  0\n",
      "160  l= 1 map_1:  1.0  map_2:  1.0\n",
      "161  l= 0 map_1:  0  map_2:  0\n",
      "162  l= 1 map_1:  0.333333333333  map_2:  0.25\n",
      "163  l= 1 map_1:  0.333333333333  map_2:  0.047619047619\n",
      "164  l= 0 map_1:  0  map_2:  0\n",
      "165  l= 0 map_1:  0  map_2:  0\n",
      "166  l= 0 map_1:  0  map_2:  0\n",
      "167  l= 0 map_1:  0  map_2:  0\n",
      "168  l= 0 map_1:  0  map_2:  0\n",
      "169  l= 1 map_1:  1.0  map_2:  1.0\n",
      "170  l= 0 map_1:  0  map_2:  0\n",
      "171  l= 4 map_1:  0.625  map_2:  0.54375\n",
      "172  l= 0 map_1:  0  map_2:  0\n",
      "173  l= 0 map_1:  0  map_2:  0\n",
      "174  l= 0 map_1:  0  map_2:  0\n",
      "175  l= 0 map_1:  0  map_2:  0\n",
      "176  l= 0 map_1:  0  map_2:  0\n",
      "177  l= 1 map_1:  1.0  map_2:  1.0\n",
      "178  l= 0 map_1:  0  map_2:  0\n",
      "179  l= 0 map_1:  0  map_2:  0\n",
      "180  l= 0 map_1:  0  map_2:  0\n",
      "181  l= 0 map_1:  0  map_2:  0\n",
      "182  l= 0 map_1:  0  map_2:  0\n",
      "183  l= 0 map_1:  0  map_2:  0\n",
      "184  l= 3 map_1:  0.303571428571  map_2:  0.320634920635\n",
      "185  l= 0 map_1:  0  map_2:  0\n",
      "186  l= 0 map_1:  0  map_2:  0\n",
      "187  l= 0 map_1:  0  map_2:  0\n",
      "188  l= 0 map_1:  0  map_2:  0\n",
      "189  l= 2 map_1:  0.5  map_2:  0.583333333333\n",
      "190  l= 1 map_1:  0.333333333333  map_2:  0.166666666667\n",
      "191  l= 0 map_1:  0  map_2:  0\n",
      "192  l= 0 map_1:  0  map_2:  0\n",
      "193  l= 0 map_1:  0  map_2:  0\n",
      "194  l= 0 map_1:  0  map_2:  0\n",
      "195  l= 0 map_1:  0  map_2:  0\n",
      "196  l= 0 map_1:  0  map_2:  0\n",
      "197  l= 0 map_1:  0  map_2:  0\n",
      "198  l= 0 map_1:  0  map_2:  0\n",
      "199  l= 0 map_1:  0  map_2:  0\n",
      "200  l= 0 map_1:  0  map_2:  0\n",
      "201  l= 0 map_1:  0  map_2:  0\n",
      "202  l= 1 map_1:  1.0  map_2:  1.0\n",
      "203  l= 0 map_1:  0  map_2:  0\n",
      "204  l= 0 map_1:  0  map_2:  0\n",
      "205  l= 0 map_1:  0  map_2:  0\n",
      "206  l= 0 map_1:  0  map_2:  0\n",
      "207  l= 1 map_1:  0.333333333333  map_2:  0.25\n",
      "208  l= 0 map_1:  0  map_2:  0\n",
      "209  l= 0 map_1:  0  map_2:  0\n",
      "210  l= 1 map_1:  0.142857142857  map_2:  0.125\n",
      "211  l= 0 map_1:  0  map_2:  0\n",
      "212  l= 0 map_1:  0  map_2:  0\n",
      "213  l= 1 map_1:  0.5  map_2:  0.5\n",
      "214  l= 1 map_1:  0.5  map_2:  0.5\n",
      "215  l= 2 map_1:  0.833333333333  map_2:  0.75\n",
      "216  l= 1 map_1:  0.2  map_2:  0.2\n",
      "217  l= 1 map_1:  1.0  map_2:  1.0\n",
      "218  l= 2 map_1:  0.11858974359  map_2:  0.140909090909\n",
      "219  l= 0 map_1:  0  map_2:  0\n",
      "220  l= 0 map_1:  0  map_2:  0\n",
      "221  l= 0 map_1:  0  map_2:  0\n",
      "222  l= 1 map_1:  1.0  map_2:  1.0\n",
      "223  l= 0 map_1:  0  map_2:  0\n",
      "224  l= 0 map_1:  0  map_2:  0\n",
      "225  l= 1 map_1:  0.125  map_2:  0.333333333333\n",
      "226  l= 1 map_1:  0.2  map_2:  0.2\n",
      "227  l= 1 map_1:  0.125  map_2:  0.5\n",
      "228  l= 0 map_1:  0  map_2:  0\n",
      "229  l= 0 map_1:  0  map_2:  0\n",
      "230  l= 0 map_1:  0  map_2:  0\n",
      "231  l= 0 map_1:  0  map_2:  0\n",
      "232  l= 0 map_1:  0  map_2:  0\n",
      "233  l= 0 map_1:  0  map_2:  0\n",
      "234  l= 0 map_1:  0  map_2:  0\n",
      "235  l= 0 map_1:  0  map_2:  0\n",
      "236  l= 0 map_1:  0  map_2:  0\n",
      "237  l= 0 map_1:  0  map_2:  0\n",
      "238  l= 0 map_1:  0  map_2:  0\n",
      "239  l= 0 map_1:  0  map_2:  0\n",
      "240  l= 1 map_1:  0.5  map_2:  0.125\n",
      "241  l= 2 map_1:  0.333333333333  map_2:  0.309523809524\n",
      "242  l= 2 map_1:  0.833333333333  map_2:  0.833333333333\n",
      "243  l= 1 map_1:  0.333333333333  map_2:  0.333333333333\n",
      "244  l= 0 map_1:  0  map_2:  0\n",
      "245  l= 1 map_1:  1.0  map_2:  1.0\n",
      "246  l= 1 map_1:  1.0  map_2:  1.0\n",
      "247  l= 0 map_1:  0  map_2:  0\n",
      "248  l= 1 map_1:  1.0  map_2:  1.0\n",
      "249  l= 0 map_1:  0  map_2:  0\n",
      "250  l= 0 map_1:  0  map_2:  0\n",
      "251  l= 0 map_1:  0  map_2:  0\n",
      "252  l= 1 map_1:  0.2  map_2:  0.25\n",
      "253  l= 1 map_1:  0.111111111111  map_2:  0.111111111111\n",
      "254  l= 1 map_1:  0.333333333333  map_2:  0.333333333333\n",
      "255  l= 1 map_1:  0.5  map_2:  0.333333333333\n",
      "256  l= 0 map_1:  0  map_2:  0\n",
      "257  l= 1 map_1:  1.0  map_2:  1.0\n",
      "258  l= 1 map_1:  0.2  map_2:  0.0769230769231\n",
      "259  l= 0 map_1:  0  map_2:  0\n",
      "260  l= 2 map_1:  0.5  map_2:  0.45\n",
      "261  l= 1 map_1:  0.5  map_2:  0.2\n",
      "262  l= 1 map_1:  0.25  map_2:  0.5\n",
      "263  l= 0 map_1:  0  map_2:  0\n",
      "264  l= 0 map_1:  0  map_2:  0\n",
      "265  l= 0 map_1:  0  map_2:  0\n",
      "266  l= 0 map_1:  0  map_2:  0\n",
      "267  l= 1 map_1:  1.0  map_2:  1.0\n",
      "268  l= 0 map_1:  0  map_2:  0\n",
      "269  l= 1 map_1:  0.2  map_2:  0.0833333333333\n",
      "270  l= 0 map_1:  0  map_2:  0\n",
      "271  l= 1 map_1:  0.5  map_2:  0.142857142857\n",
      "272  l= 1 map_1:  0.5  map_2:  0.2\n",
      "273  l= 0 map_1:  0  map_2:  0\n",
      "274  l= 0 map_1:  0  map_2:  0\n",
      "275  l= 1 map_1:  1.0  map_2:  1.0\n",
      "276  l= 1 map_1:  1.0  map_2:  1.0\n",
      "277  l= 1 map_1:  1.0  map_2:  1.0\n",
      "278  l= 0 map_1:  0  map_2:  0\n",
      "279  l= 2 map_1:  0.148351648352  map_2:  0.139423076923\n",
      "280  l= 0 map_1:  0  map_2:  0\n",
      "281  l= 1 map_1:  0.5  map_2:  0.333333333333\n",
      "282  l= 1 map_1:  1.0  map_2:  1.0\n",
      "283  l= 0 map_1:  0  map_2:  0\n",
      "284  l= 0 map_1:  0  map_2:  0\n",
      "285  l= 1 map_1:  0.25  map_2:  0.25\n",
      "286  l= 1 map_1:  1.0  map_2:  1.0\n",
      "287  l= 0 map_1:  0  map_2:  0\n",
      "288  l= 0 map_1:  0  map_2:  0\n",
      "289  l= 1 map_1:  0.333333333333  map_2:  0.333333333333\n",
      "290  l= 2 map_1:  0.5  map_2:  0.291666666667\n",
      "291  l= 1 map_1:  1.0  map_2:  1.0\n",
      "292  l= 0 map_1:  0  map_2:  0\n",
      "293  l= 0 map_1:  0  map_2:  0\n",
      "294  l= 1 map_1:  1.0  map_2:  1.0\n",
      "295  l= 1 map_1:  1.0  map_2:  1.0\n",
      "296  l= 0 map_1:  0  map_2:  0\n",
      "297  l= 0 map_1:  0  map_2:  0\n",
      "298  l= 1 map_1:  1.0  map_2:  1.0\n",
      "299  l= 1 map_1:  0.5  map_2:  0.333333333333\n",
      "300  l= 0 map_1:  0  map_2:  0\n",
      "301  l= 1 map_1:  0.0833333333333  map_2:  0.04\n",
      "302  l= 1 map_1:  0.142857142857  map_2:  0.1\n",
      "303  l= 1 map_1:  0.142857142857  map_2:  0.2\n",
      "304  l= 0 map_1:  0  map_2:  0\n",
      "305  l= 1 map_1:  1.0  map_2:  1.0\n",
      "306  l= 3 map_1:  0.777777777778  map_2:  0.777777777778\n",
      "307  l= 0 map_1:  0  map_2:  0\n",
      "308  l= 2 map_1:  1.0  map_2:  1.0\n",
      "309  l= 0 map_1:  0  map_2:  0\n",
      "310  l= 1 map_1:  0.25  map_2:  0.125\n",
      "311  l= 0 map_1:  0  map_2:  0\n",
      "312  l= 0 map_1:  0  map_2:  0\n",
      "313  l= 1 map_1:  1.0  map_2:  1.0\n",
      "314  l= 1 map_1:  1.0  map_2:  1.0\n",
      "315  l= 0 map_1:  0  map_2:  0\n",
      "316  l= 0 map_1:  0  map_2:  0\n",
      "317  l= 0 map_1:  0  map_2:  0\n",
      "318  l= 1 map_1:  1.0  map_2:  1.0\n",
      "319  l= 1 map_1:  0.5  map_2:  0.5\n",
      "320  l= 1 map_1:  1.0  map_2:  1.0\n",
      "321  l= 1 map_1:  1.0  map_2:  1.0\n",
      "322  l= 0 map_1:  0  map_2:  0\n",
      "323  l= 0 map_1:  0  map_2:  0\n",
      "324  l= 0 map_1:  0  map_2:  0\n",
      "325  l= 1 map_1:  0.5  map_2:  0.5\n",
      "326  l= 0 map_1:  0  map_2:  0\n",
      "327  l= 1 map_1:  1.0  map_2:  1.0\n",
      "328  l= 0 map_1:  0  map_2:  0\n",
      "329  l= 0 map_1:  0  map_2:  0\n",
      "330  l= 0 map_1:  0  map_2:  0\n",
      "331  l= 0 map_1:  0  map_2:  0\n",
      "332  l= 0 map_1:  0  map_2:  0\n",
      "333  l= 0 map_1:  0  map_2:  0\n",
      "334  l= 0 map_1:  0  map_2:  0\n",
      "335  l= 1 map_1:  0.5  map_2:  0.25\n",
      "336  l= 1 map_1:  0.5  map_2:  0.25\n",
      "337  l= 0 map_1:  0  map_2:  0\n",
      "338  l= 1 map_1:  0.25  map_2:  0.2\n",
      "339  l= 0 map_1:  0  map_2:  0\n",
      "340  l= 0 map_1:  0  map_2:  0\n",
      "341  l= 0 map_1:  0  map_2:  0\n",
      "342  l= 0 map_1:  0  map_2:  0\n",
      "343  l= 1 map_1:  1.0  map_2:  1.0\n",
      "344  l= 0 map_1:  0  map_2:  0\n",
      "345  l= 0 map_1:  0  map_2:  0\n",
      "346  l= 1 map_1:  1.0  map_2:  1.0\n",
      "347  l= 0 map_1:  0  map_2:  0\n",
      "348  l= 1 map_1:  0.5  map_2:  0.5\n",
      "349  l= 1 map_1:  1.0  map_2:  1.0\n",
      "350  l= 0 map_1:  0  map_2:  0\n",
      "351  l= 0 map_1:  0  map_2:  0\n",
      "352  l= 0 map_1:  0  map_2:  0\n",
      "353  l= 1 map_1:  1.0  map_2:  1.0\n",
      "354  l= 1 map_1:  0.333333333333  map_2:  0.333333333333\n",
      "355  l= 0 map_1:  0  map_2:  0\n",
      "356  l= 0 map_1:  0  map_2:  0\n",
      "357  l= 1 map_1:  0.25  map_2:  0.25\n",
      "358  l= 1 map_1:  0.5  map_2:  0.5\n",
      "359  l= 1 map_1:  0.333333333333  map_2:  0.0769230769231\n",
      "360  l= 2 map_1:  0.5  map_2:  0.583333333333\n",
      "361  l= 0 map_1:  0  map_2:  0\n",
      "362  l= 0 map_1:  0  map_2:  0\n",
      "363  l= 1 map_1:  0.5  map_2:  0.5\n",
      "364  l= 1 map_1:  0.2  map_2:  0.25\n",
      "365  l= 0 map_1:  0  map_2:  0\n",
      "366  l= 0 map_1:  0  map_2:  0\n",
      "367  l= 1 map_1:  0.5  map_2:  0.5\n",
      "368  l= 1 map_1:  1.0  map_2:  1.0\n",
      "369  l= 0 map_1:  0  map_2:  0\n",
      "370  l= 1 map_1:  0.166666666667  map_2:  0.2\n",
      "371  l= 0 map_1:  0  map_2:  0\n",
      "372  l= 0 map_1:  0  map_2:  0\n",
      "373  l= 1 map_1:  0.25  map_2:  0.25\n",
      "374  l= 1 map_1:  0.333333333333  map_2:  0.333333333333\n",
      "375  l= 2 map_1:  1.0  map_2:  1.0\n",
      "376  l= 1 map_1:  0.5  map_2:  0.5\n",
      "377  l= 0 map_1:  0  map_2:  0\n",
      "378  l= 0 map_1:  0  map_2:  0\n",
      "379  l= 0 map_1:  0  map_2:  0\n",
      "380  l= 0 map_1:  0  map_2:  0\n",
      "381  l= 0 map_1:  0  map_2:  0\n",
      "382  l= 0 map_1:  0  map_2:  0\n",
      "383  l= 1 map_1:  0.166666666667  map_2:  0.333333333333\n",
      "384  l= 1 map_1:  1.0  map_2:  1.0\n",
      "385  l= 1 map_1:  1.0  map_2:  1.0\n",
      "386  l= 0 map_1:  0  map_2:  0\n",
      "387  l= 0 map_1:  0  map_2:  0\n",
      "388  l= 0 map_1:  0  map_2:  0\n",
      "389  l= 0 map_1:  0  map_2:  0\n",
      "390  l= 0 map_1:  0  map_2:  0\n",
      "391  l= 0 map_1:  0  map_2:  0\n",
      "392  l= 0 map_1:  0  map_2:  0\n",
      "393  l= 0 map_1:  0  map_2:  0\n",
      "394  l= 0 map_1:  0  map_2:  0\n",
      "395  l= 0 map_1:  0  map_2:  0\n",
      "396  l= 4 map_1:  0.220820845821  map_2:  0.316666666667\n",
      "397  l= 1 map_1:  1.0  map_2:  1.0\n",
      "398  l= 0 map_1:  0  map_2:  0\n",
      "399  l= 0 map_1:  0  map_2:  0\n",
      "400  l= 0 map_1:  0  map_2:  0\n",
      "401  l= 1 map_1:  0.166666666667  map_2:  0.166666666667\n",
      "402  l= 0 map_1:  0  map_2:  0\n",
      "403  l= 0 map_1:  0  map_2:  0\n",
      "404  l= 1 map_1:  1.0  map_2:  1.0\n",
      "405  l= 0 map_1:  0  map_2:  0\n",
      "406  l= 1 map_1:  0.142857142857  map_2:  0.111111111111\n",
      "407  l= 1 map_1:  0.0769230769231  map_2:  0.111111111111\n",
      "408  l= 1 map_1:  1.0  map_2:  1.0\n",
      "409  l= 0 map_1:  0  map_2:  0\n",
      "410  l= 0 map_1:  0  map_2:  0\n",
      "411  l= 0 map_1:  0  map_2:  0\n",
      "412  l= 1 map_1:  0.0526315789474  map_2:  0.0909090909091\n",
      "413  l= 0 map_1:  0  map_2:  0\n",
      "414  l= 0 map_1:  0  map_2:  0\n",
      "415  l= 1 map_1:  0.5  map_2:  0.5\n",
      "416  l= 1 map_1:  1.0  map_2:  1.0\n",
      "417  l= 0 map_1:  0  map_2:  0\n",
      "418  l= 1 map_1:  0.05  map_2:  0.047619047619\n",
      "419  l= 0 map_1:  0  map_2:  0\n",
      "420  l= 0 map_1:  0  map_2:  0\n",
      "421  l= 4 map_1:  0.770833333333  map_2:  0.770833333333\n",
      "422  l= 1 map_1:  1.0  map_2:  1.0\n",
      "423  l= 0 map_1:  0  map_2:  0\n",
      "424  l= 0 map_1:  0  map_2:  0\n",
      "425  l= 0 map_1:  0  map_2:  0\n",
      "426  l= 0 map_1:  0  map_2:  0\n",
      "427  l= 1 map_1:  1.0  map_2:  1.0\n",
      "428  l= 1 map_1:  1.0  map_2:  1.0\n",
      "429  l= 0 map_1:  0  map_2:  0\n",
      "430  l= 0 map_1:  0  map_2:  0\n",
      "431  l= 1 map_1:  0.0909090909091  map_2:  0.142857142857\n",
      "432  l= 1 map_1:  0.5  map_2:  0.25\n",
      "433  l= 1 map_1:  0.333333333333  map_2:  0.5\n",
      "434  l= 2 map_1:  0.833333333333  map_2:  0.833333333333\n",
      "435  l= 0 map_1:  0  map_2:  0\n",
      "436  l= 0 map_1:  0  map_2:  0\n",
      "437  l= 1 map_1:  0.111111111111  map_2:  0.0833333333333\n",
      "438  l= 0 map_1:  0  map_2:  0\n",
      "439  l= 1 map_1:  0.333333333333  map_2:  0.5\n",
      "440  l= 0 map_1:  0  map_2:  0\n",
      "441  l= 0 map_1:  0  map_2:  0\n",
      "442  l= 0 map_1:  0  map_2:  0\n",
      "443  l= 0 map_1:  0  map_2:  0\n",
      "444  l= 1 map_1:  1.0  map_2:  1.0\n",
      "445  l= 0 map_1:  0  map_2:  0\n",
      "446  l= 1 map_1:  1.0  map_2:  1.0\n",
      "447  l= 0 map_1:  0  map_2:  0\n",
      "448  l= 0 map_1:  0  map_2:  0\n",
      "449  l= 0 map_1:  0  map_2:  0\n",
      "450  l= 1 map_1:  1.0  map_2:  1.0\n",
      "451  l= 0 map_1:  0  map_2:  0\n",
      "452  l= 0 map_1:  0  map_2:  0\n",
      "453  l= 0 map_1:  0  map_2:  0\n",
      "454  l= 0 map_1:  0  map_2:  0\n",
      "455  l= 0 map_1:  0  map_2:  0\n",
      "456  l= 0 map_1:  0  map_2:  0\n",
      "457  l= 0 map_1:  0  map_2:  0\n",
      "458  l= 1 map_1:  1.0  map_2:  1.0\n",
      "459  l= 0 map_1:  0  map_2:  0\n",
      "460  l= 0 map_1:  0  map_2:  0\n",
      "461  l= 1 map_1:  1.0  map_2:  1.0\n",
      "462  l= 0 map_1:  0  map_2:  0\n",
      "463  l= 1 map_1:  0.166666666667  map_2:  0.25\n",
      "464  l= 1 map_1:  0.5  map_2:  0.5\n",
      "465  l= 0 map_1:  0  map_2:  0\n",
      "466  l= 0 map_1:  0  map_2:  0\n",
      "467  l= 1 map_1:  1.0  map_2:  1.0\n",
      "468  l= 0 map_1:  0  map_2:  0\n",
      "469  l= 2 map_1:  0.266666666667  map_2:  0.333333333333\n",
      "470  l= 1 map_1:  0.333333333333  map_2:  0.5\n",
      "471  l= 1 map_1:  0.166666666667  map_2:  0.166666666667\n",
      "472  l= 0 map_1:  0  map_2:  0\n",
      "473  l= 0 map_1:  0  map_2:  0\n",
      "474  l= 3 map_1:  0.411111111111  map_2:  0.411111111111\n",
      "475  l= 1 map_1:  1.0  map_2:  1.0\n",
      "476  l= 1 map_1:  1.0  map_2:  1.0\n",
      "477  l= 0 map_1:  0  map_2:  0\n",
      "478  l= 1 map_1:  1.0  map_2:  1.0\n",
      "479  l= 0 map_1:  0  map_2:  0\n",
      "480  l= 0 map_1:  0  map_2:  0\n",
      "481  l= 1 map_1:  1.0  map_2:  1.0\n",
      "482  l= 0 map_1:  0  map_2:  0\n",
      "483  l= 1 map_1:  1.0  map_2:  1.0\n",
      "484  l= 1 map_1:  1.0  map_2:  1.0\n",
      "485  l= 0 map_1:  0  map_2:  0\n",
      "486  l= 0 map_1:  0  map_2:  0\n",
      "487  l= 0 map_1:  0  map_2:  0\n",
      "488  l= 1 map_1:  1.0  map_2:  1.0\n",
      "489  l= 1 map_1:  0.25  map_2:  0.333333333333\n",
      "490  l= 0 map_1:  0  map_2:  0\n",
      "491  l= 2 map_1:  0.833333333333  map_2:  0.833333333333\n",
      "492  l= 1 map_1:  1.0  map_2:  1.0\n",
      "493  l= 0 map_1:  0  map_2:  0\n",
      "494  l= 1 map_1:  1.0  map_2:  1.0\n",
      "495  l= 1 map_1:  0.2  map_2:  0.2\n",
      "496  l= 0 map_1:  0  map_2:  0\n",
      "497  l= 0 map_1:  0  map_2:  0\n",
      "498  l= 0 map_1:  0  map_2:  0\n",
      "499  l= 0 map_1:  0  map_2:  0\n",
      "500  l= 0 map_1:  0  map_2:  0\n",
      "501  l= 1 map_1:  0.5  map_2:  0.5\n",
      "502  l= 0 map_1:  0  map_2:  0\n",
      "503  l= 1 map_1:  1.0  map_2:  1.0\n",
      "504  l= 0 map_1:  0  map_2:  0\n",
      "505  l= 1 map_1:  0.25  map_2:  0.25\n",
      "506  l= 0 map_1:  0  map_2:  0\n",
      "507  l= 0 map_1:  0  map_2:  0\n",
      "508  l= 1 map_1:  1.0  map_2:  1.0\n",
      "509  l= 0 map_1:  0  map_2:  0\n",
      "510  l= 1 map_1:  1.0  map_2:  1.0\n",
      "511  l= 0 map_1:  0  map_2:  0\n",
      "512  l= 0 map_1:  0  map_2:  0\n",
      "513  l= 0 map_1:  0  map_2:  0\n",
      "514  l= 1 map_1:  0.333333333333  map_2:  0.25\n",
      "515  l= 0 map_1:  0  map_2:  0\n",
      "516  l= 0 map_1:  0  map_2:  0\n",
      "517  l= 0 map_1:  0  map_2:  0\n",
      "518  l= 1 map_1:  1.0  map_2:  1.0\n",
      "519  l= 0 map_1:  0  map_2:  0\n",
      "520  l= 1 map_1:  1.0  map_2:  1.0\n",
      "521  l= 1 map_1:  0.5  map_2:  0.333333333333\n",
      "522  l= 0 map_1:  0  map_2:  0\n",
      "523  l= 0 map_1:  0  map_2:  0\n",
      "524  l= 0 map_1:  0  map_2:  0\n",
      "525  l= 0 map_1:  0  map_2:  0\n",
      "526  l= 0 map_1:  0  map_2:  0\n",
      "527  l= 0 map_1:  0  map_2:  0\n",
      "528  l= 0 map_1:  0  map_2:  0\n",
      "529  l= 0 map_1:  0  map_2:  0\n",
      "530  l= 1 map_1:  1.0  map_2:  1.0\n",
      "531  l= 2 map_1:  1.0  map_2:  1.0\n",
      "532  l= 0 map_1:  0  map_2:  0\n",
      "533  l= 0 map_1:  0  map_2:  0\n",
      "534  l= 0 map_1:  0  map_2:  0\n",
      "535  l= 0 map_1:  0  map_2:  0\n",
      "536  l= 0 map_1:  0  map_2:  0\n",
      "537  l= 0 map_1:  0  map_2:  0\n",
      "538  l= 0 map_1:  0  map_2:  0\n",
      "539  l= 0 map_1:  0  map_2:  0\n",
      "540  l= 0 map_1:  0  map_2:  0\n",
      "541  l= 0 map_1:  0  map_2:  0\n",
      "542  l= 0 map_1:  0  map_2:  0\n",
      "543  l= 0 map_1:  0  map_2:  0\n",
      "544  l= 0 map_1:  0  map_2:  0\n",
      "545  l= 1 map_1:  0.142857142857  map_2:  0.2\n",
      "546  l= 1 map_1:  0.111111111111  map_2:  0.125\n",
      "547  l= 0 map_1:  0  map_2:  0\n",
      "548  l= 0 map_1:  0  map_2:  0\n",
      "549  l= 0 map_1:  0  map_2:  0\n",
      "550  l= 1 map_1:  1.0  map_2:  1.0\n",
      "551  l= 0 map_1:  0  map_2:  0\n",
      "552  l= 0 map_1:  0  map_2:  0\n",
      "553  l= 1 map_1:  0.25  map_2:  0.2\n",
      "554  l= 0 map_1:  0  map_2:  0\n",
      "555  l= 1 map_1:  1.0  map_2:  1.0\n",
      "556  l= 1 map_1:  0.2  map_2:  0.25\n",
      "557  l= 1 map_1:  0.5  map_2:  0.1\n",
      "558  l= 1 map_1:  0.25  map_2:  0.25\n",
      "559  l= 0 map_1:  0  map_2:  0\n",
      "560  l= 0 map_1:  0  map_2:  0\n",
      "561  l= 0 map_1:  0  map_2:  0\n",
      "562  l= 0 map_1:  0  map_2:  0\n",
      "563  l= 0 map_1:  0  map_2:  0\n",
      "564  l= 0 map_1:  0  map_2:  0\n",
      "565  l= 0 map_1:  0  map_2:  0\n",
      "566  l= 1 map_1:  0.333333333333  map_2:  0.2\n",
      "567  l= 0 map_1:  0  map_2:  0\n",
      "568  l= 1 map_1:  1.0  map_2:  1.0\n",
      "569  l= 0 map_1:  0  map_2:  0\n",
      "570  l= 1 map_1:  0.142857142857  map_2:  0.1\n",
      "571  l= 0 map_1:  0  map_2:  0\n",
      "572  l= 0 map_1:  0  map_2:  0\n",
      "573  l= 0 map_1:  0  map_2:  0\n",
      "574  l= 0 map_1:  0  map_2:  0\n",
      "575  l= 0 map_1:  0  map_2:  0\n",
      "576  l= 1 map_1:  1.0  map_2:  1.0\n",
      "577  l= 0 map_1:  0  map_2:  0\n",
      "578  l= 0 map_1:  0  map_2:  0\n",
      "579  l= 1 map_1:  0.1  map_2:  0.142857142857\n",
      "580  l= 0 map_1:  0  map_2:  0\n",
      "581  l= 0 map_1:  0  map_2:  0\n",
      "582  l= 0 map_1:  0  map_2:  0\n",
      "583  l= 1 map_1:  1.0  map_2:  1.0\n",
      "584  l= 0 map_1:  0  map_2:  0\n",
      "585  l= 0 map_1:  0  map_2:  0\n",
      "586  l= 0 map_1:  0  map_2:  0\n",
      "587  l= 0 map_1:  0  map_2:  0\n",
      "588  l= 1 map_1:  1.0  map_2:  1.0\n",
      "589  l= 0 map_1:  0  map_2:  0\n",
      "590  l= 0 map_1:  0  map_2:  0\n",
      "591  l= 1 map_1:  0.333333333333  map_2:  0.333333333333\n",
      "592  l= 0 map_1:  0  map_2:  0\n",
      "593  l= 0 map_1:  0  map_2:  0\n",
      "594  l= 0 map_1:  0  map_2:  0\n",
      "595  l= 1 map_1:  1.0  map_2:  1.0\n",
      "596  l= 1 map_1:  0.0833333333333  map_2:  0.0714285714286\n",
      "597  l= 0 map_1:  0  map_2:  0\n",
      "598  l= 0 map_1:  0  map_2:  0\n",
      "599  l= 0 map_1:  0  map_2:  0\n",
      "600  l= 0 map_1:  0  map_2:  0\n",
      "601  l= 1 map_1:  0.142857142857  map_2:  0.0909090909091\n",
      "602  l= 0 map_1:  0  map_2:  0\n",
      "603  l= 1 map_1:  0.166666666667  map_2:  0.166666666667\n",
      "604  l= 1 map_1:  0.5  map_2:  0.333333333333\n",
      "605  l= 4 map_1:  0.192568922306  map_2:  0.166369047619\n",
      "606  l= 0 map_1:  0  map_2:  0\n",
      "607  l= 1 map_1:  0.5  map_2:  0.5\n",
      "608  l= 1 map_1:  0.0625  map_2:  0.0588235294118\n",
      "609  l= 2 map_1:  1.0  map_2:  1.0\n",
      "610  l= 0 map_1:  0  map_2:  0\n",
      "611  l= 0 map_1:  0  map_2:  0\n",
      "612  l= 0 map_1:  0  map_2:  0\n",
      "613  l= 1 map_1:  0.5  map_2:  0.5\n",
      "614  l= 0 map_1:  0  map_2:  0\n",
      "615  l= 0 map_1:  0  map_2:  0\n",
      "616  l= 0 map_1:  0  map_2:  0\n",
      "617  l= 0 map_1:  0  map_2:  0\n",
      "618  l= 0 map_1:  0  map_2:  0\n",
      "619  l= 0 map_1:  0  map_2:  0\n",
      "620  l= 1 map_1:  1.0  map_2:  1.0\n",
      "621  l= 0 map_1:  0  map_2:  0\n",
      "622  l= 0 map_1:  0  map_2:  0\n",
      "623  l= 1 map_1:  1.0  map_2:  1.0\n",
      "624  l= 1 map_1:  0.142857142857  map_2:  0.142857142857\n",
      "625  l= 1 map_1:  1.0  map_2:  1.0\n",
      "626  l= 1 map_1:  1.0  map_2:  1.0\n",
      "627  l= 0 map_1:  0  map_2:  0\n",
      "628  l= 1 map_1:  0.333333333333  map_2:  0.333333333333\n",
      "629  l= 1 map_1:  1.0  map_2:  1.0\n",
      "630  l= 0 map_1:  0  map_2:  0\n",
      "631  l= 0 map_1:  0  map_2:  0\n",
      "632  l= 0 map_1:  0  map_2:  0\n"
     ]
    }
   ],
   "source": [
    "from QAData import QAPair\n",
    "\n",
    "first_map = []\n",
    "second_map = []\n",
    "final_1_predictions = []\n",
    "final_2_predictions = []\n",
    "ids_q = []\n",
    "for key,group in groupby(qa_pair['test'], lambda x: x.qi):\n",
    "    first_qapair = []\n",
    "    for qp in group:\n",
    "        first_qapair.append(qp)\n",
    "    # Get first predictions without rerank\n",
    "    first_qxa, first_l = k_model.buildCosineSimMatrix(first_qapair, max_terms=k_model.max_words)\n",
    "    first_predictions = model.predict(np.array(first_qxa))\n",
    "    first_map.append(avg_precision(first_l, first_predictions))\n",
    "    final_1_predictions.extend(first_predictions)\n",
    "    # Get second preditions taking into account the pseudo relevance feedback\n",
    "    maxq = np.argmax(first_predictions)\n",
    "    #print first_predictions\n",
    "    #q_1 = ' '.join([word for word in first_qapair[maxq].q.split() if word not in (stopwords.words('english'))])\n",
    "    if first_predictions[maxq] > 0.6:\n",
    "        a_1 = ' '.join([word for word in first_qapair[maxq].a.split() if word not in (stopwords.words('english'))])\n",
    "    else: \n",
    "        a_1 = ' '\n",
    "    #a_1 = ' '.join([word for word in first_qapair[maxq].a.split()])\n",
    "    q = ' '.join( [ word for word in qp.q.split() ] )\n",
    "    second_qapair = [ QAPair(qp.qi, q+' '+a_1,qp.ai,qp.a,qp.l) for qp in first_qapair ]\n",
    "    second_qxa, second_l = k_model.buildCosineSimMatrix(second_qapair, max_terms=k_model.max_words)\n",
    "    second_predictions = model.predict(np.array(second_qxa))\n",
    "    second_predictions[maxq] = 1.0\n",
    "    second_map.append(avg_precision(second_l, second_predictions))\n",
    "    final_2_predictions.extend(second_predictions)\n",
    "    print first_qapair[0].qi, ' l=',sum(first_l), 'map_1: ', first_map[len(first_map)-1] ,' map_2: ', second_map[len(second_map)-1]\n",
    "    #print first_map, second_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.237475862606\n"
     ]
    }
   ],
   "source": [
    "print sum(first_map)/len(first_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.232050718037\n"
     ]
    }
   ],
   "source": [
    "print sum(second_map)/len(second_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rank_file_1 = 'experiments/rankfile_1.rank'\n",
    "idx_pred = 0\n",
    "rank_text = ''\n",
    "for key,group in groupby(qa_pair['test'], lambda x: x.qi):\n",
    "    for i, qp in enumerate(group):\n",
    "        rank_text += str(qp.qi) + ' 0 ' + str(qp.ai) + ' 0 ' + str(final_2_predictions[idx_pred][0]) + ' 0\\n'\n",
    "        idx_pred += 1\n",
    "with open(rank_file_1, 'wb') as text_file:\n",
    "    text_file.write(rank_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!/home/aerossom/trec_eval.9.0/trec_eval -c /home/aerossom/passage-retrieval/experiments/gold-jakana-test2.rank experiments/rankfile_1.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runid                 \tall\t0\r\n",
      "num_q                 \tall\t237\r\n",
      "num_ret               \tall\t2341\r\n",
      "num_rel               \tall\t283\r\n",
      "num_rel_ret           \tall\t283\r\n",
      "map                   \tall\t0.5935\r\n",
      "gm_map                \tall\t0.4521\r\n",
      "Rprec                 \tall\t0.4385\r\n",
      "bpref                 \tall\t0.4340\r\n",
      "recip_rank            \tall\t0.6028\r\n",
      "iprec_at_recall_0.00  \tall\t0.6081\r\n",
      "iprec_at_recall_0.10  \tall\t0.6081\r\n",
      "iprec_at_recall_0.20  \tall\t0.6081\r\n",
      "iprec_at_recall_0.30  \tall\t0.6045\r\n",
      "iprec_at_recall_0.40  \tall\t0.6045\r\n",
      "iprec_at_recall_0.50  \tall\t0.6045\r\n",
      "iprec_at_recall_0.60  \tall\t0.5892\r\n",
      "iprec_at_recall_0.70  \tall\t0.5892\r\n",
      "iprec_at_recall_0.80  \tall\t0.5844\r\n",
      "iprec_at_recall_0.90  \tall\t0.5844\r\n",
      "iprec_at_recall_1.00  \tall\t0.5844\r\n",
      "P_5                   \tall\t0.1865\r\n",
      "P_10                  \tall\t0.1114\r\n",
      "P_15                  \tall\t0.0776\r\n",
      "P_20                  \tall\t0.0589\r\n",
      "P_30                  \tall\t0.0398\r\n",
      "P_100                 \tall\t0.0119\r\n",
      "P_200                 \tall\t0.0060\r\n",
      "P_500                 \tall\t0.0024\r\n",
      "P_1000                \tall\t0.0012\r\n"
     ]
    }
   ],
   "source": [
    "!/home/aerossom/trec_eval.9.0/trec_eval -c /home/aerossom/datasets/WikiQACorpus/WikiQA-test-filtered.ref \\\n",
    "experiments/rankfile_1.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f47bb974a617>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Print learning history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Print learning history\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAP': [0.50040411122804629, 0.52189223593768197, 0.55762187871781732],\n",
       " 'MRR': [0.5037535065417272, 0.5279446569060693, 0.5645427026029268],\n",
       " 'acc': [0.4765625, 0.4921875, 0.54296875],\n",
       " 'loss': [0.25362694263458252, 0.25330552458763123, 0.24734991788864136],\n",
       " 'val_acc': [0.5, 0.515625, 0.484375],\n",
       " 'val_loss': [0.25115877389907837, 0.24868617951869965, 0.24784004688262939]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('out_file', 'wb') as output:\n",
    "    pickle.dump(history.history, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiAAAAFkCAYAAAAZqID7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAAFttJREFUeJzt3W2QZFd9HvDnL1agrFIa7AgkY4MBI7Pr2I6YicCUYwUc\n3uyKjU1SxgNbkCI4gSgBjysOAZOiwB9cImWGgOW3cgIiC1MhVIWEGATGQGEIb94hlstMEzmFACMQ\nlhCjiEEGsycfuhd6R6Pd2aXn3N6d369qa+aevrfPf86c3X369O17q7UWAICeLhi6AABg/xFAAIDu\nBBAAoDsBBADoTgABALoTQACA7gQQAKA7AQQA6E4AAQC6E0AAgO5mGkCq6uqqeltVfa6qjlfVU0+x\n729P9nnhLGsAAObfrFdADib5eJJrJts73mimqn42yWOS3HJv+wAA568Ds3yy1toNSW5IkqracZ+q\n+u4kr0nypCRvn2X/AMC5oes5IFV1QZL/nOSVrbWNnn0DAPNjpisgu/CiJF9rrb12NztX1d9K8uQk\nNye5ew/rAoDzzUVJHprkna212weu5R66BZCqWkrygiSL2x86xWFPTvLGPSsKAM5/z0zypqGL2K7n\nCsiPJXlgks9MnR9ynyS/XlUvbK09fIdjbk6So0eP5vDhw12KPB+srKxkdXV16DLOOcbtzBmzs2Pc\nzpwxO3MbGxs5cuRIMvm/dN70DCBvSPKuqe1K8s5J++vu5Zi7k+Tw4cNZXNy+cMK9WVhYMF5nwbid\nOWN2dozbmTNm35a5PIVhpgGkqi5OcsVU08Or6sokt7fWPpvkS9v2/3qSL7TWbpplHQDAfJv1CshV\nSd4z+b4ledXk+9cnec6M+wIAzlGzvg7I+3IGH+1trT1slv0DAOcG94I5Dy0vLw9dwjnJuJ05Y3Z2\njNuZM2bnn2ptfq+EXlWLSY4dO3bMyUcAcAbW19eztLSUJEuttfWh69nOCggA0J0AAgB0J4AAAN0J\nIABAdwIIANCdAAIAdCeAAADdCSAAQHcCCADQnQACAHQngAAA3QkgAEB3AggA0J0AAgB0d2DoAgBg\nL21tbWU0Gg1aw6FDh3Lw4MFBa5g3AggA57XRaJSlpaVBazh27FgWFxcHrWHeCCAA7AtHkxzu3OdG\nkiOd+zxXCCAA7AuHk1iDmB9OQgUAuhNAAIDuBBAAoDsBBADoTgABALoTQACA7gQQAKA7AQQA6E4A\nAQC6E0AAgO4EEACgOwEEAOhOAAEAupt5AKmqq6vqbVX1uao6XlVPnXrsQFVdW1U3VtVdk32ur6rv\nmnUdAMD82osVkINJPp7kmsl2m3rs4iSPSvKKydenJXlkkv+xB3UAAHPqwKyfsLV2Q5IbkqSqtj+2\nmeRJ021V9S+TfLSqvqe19hezrgcAmD/zcA7I/TNeJfny0IUAAH0MGkCq6qIk1yZ5U2vtriFrAQD6\nmflbMLtVVRcmeXPGqx/PH6oOYBhbW1sZjUaD1nDo0KEcPHhw0BpgvxokgEyFjwcn+fHTrX6srKxk\nYWHhpLbl5eUsLy/vXZHAnhqNRllaWhq0hmPHjmVxcXHQGmAW1tbWsra2dlLb5ubmQNXsTvcAMhU+\nvi/J41trd5zumNXVVf9IwHnqaJLDnfvcSHKkc5+wl3Z6Ub6+vj54yD+VmQeQqro4yRVTTQ+vqiuT\n3J7k80nekvFHcP9hkgur6vLJfre31r4+63qA+XY4iZcXsP/sxQrIVUneM/m+JXnV5PvXJ3l5kp+a\ntP/vqWNakscnef8e1AMAzJm9uA7I+3LqT9fMw0d/AYABCQMAQHcCCADQnQACAHQngAAA3QkgAEB3\nAggA0J0AAgB0J4AAAN0JIABAdwIIANCdAAIAdCeAAADdCSAAQHcCCADQnQACAHQngAAA3R0YugDm\ny9bWVkaj0aA1HDp0KAcPHhy0BgD2lgDCSUajUZaWlgat4dixY1lcXBy0BgD2lgDCjo4mOdy5z40k\nRzr3CcAwBBB2dDiJNQgA9oqTUAGA7gQQAKA7AQQA6E4AAQC6E0AAgO4EEACgOwEEAOhOAAEAuhNA\nAIDuBBAAoDsBBADoTgABALoTQACA7gQQAKC7mQaQqrq6qt5WVZ+rquNV9dQd9nlFVd1SVVtV9QdV\n9YhZ1gAAzL9Zr4AcTPLxJNdMttv0g1X1oiT/Ksk/T/KYJF9J8s6qut+M6wAA5tiBWT5Za+2GJDck\nSVWd9FiNG34xya+21t42aXtWkluT/EyS/zLLWgCA+dXzHJCHJbksybtPNLTW7kzykSSP7VgHADCw\nngHk8snXW7e13zr1GACwD8z0LZizVEmOn2qHlZWVLCwsnNS2vLyc5eXlvawLAM4Ja2trWVtbO6lt\nc3NzoGp2p2cA+cLk62U5eRXksiTrpzpwdXU1i4uLe1UXAJzTdnpRvr6+nqWlpYEqOr2eb8F8KuMQ\n8oQTDVV1SZJHJ/lQxzoAgIHNdAWkqi5OcsVU08Or6sokt7fWPltVr07y0qq6KcnNSX41yeeSvHWW\ndQAA823Wb8FcleQ9k+9bkldNvn99kue01l45CSm/m+T+Sf4oyVNaa1+bcR0AwByb9XVA3pfTvK3T\nWntZkpfNsl8A4NziXjAAQHcCCADQnQACAHQngAAA3QkgAEB3AggA0J0AAgB0J4AAAN0JIABAdwII\nANCdAAIAdCeAAADdCSAAQHcCCADQnQACAHR3YOgCYL/b2trKaDQatIZDhw7l4MGDg9YA7C8CCAxs\nNBplaWlp0BqOHTuWxcXFQWsA9hcBBObG0SSHO/e5keRI5z4BBBCYI4eTWIUA9gcnoQIA3QkgAEB3\nAggA0J0AAgB0J4AAAN0JIABAdwIIANCdAAIAdCeAAADdCSAAQHcCCADQnQACAHQngAAA3QkgAEB3\nXQNIVR2oql+rqk9V1VZV/XlVvbRnDQDA8A507u8lSZ6b5FlJ/izJVUleV1WbrbXXdq4FABhI7wBy\nVZK3ttbeMdn+TFU9Y9IOAOwTvc8BeUeSJ1TVFUlSVX8nyY9O2gGAfaLrCkhr7Ter6iFJPllVf53k\nPkle0lpb61kHADCsrgGkql6Q5NlJfj7jc0AeleTVVfX51tob7u24lZWVLCwsnNS2vLyc5eXlvSwX\nAM4Ja2trWVs7+bX85ubmQNXsTu9zQH4lyctba2+ebP9ZVX1vkhcnudcAsrq6msXFxR71AcA5Z6cX\n5evr61laWhqootPrfQ5IJfnGtrbjk3YAYJ/ovQLy1iQvrarPJvlExm/BrCT5j53rAAAG1DuArCS5\nM8l1SS5LckuS307yis51AAAD6v0pmK8k+deTPwDAPuVeMABAdwIIANCdAAIAdCeAAADdCSAAQHcC\nCADQnQACAHQngAAA3QkgAEB3AggA0J0AAgB0J4AAAN0JIABAdwIIANCdAAIAdCeAAADdCSAAQHcC\nCADQnQACAHQngAAA3QkgAEB3AggA0J0AAgB0J4AAAN0JIABAdwIIANCdAAIAdCeAAADdCSAAQHcC\nCADQnQACAHQngAAA3QkgAEB33QNIVX13VR2tqtuqaquqbqyqpd51AADDOdCzs6r6jiQfTPKHSZ6S\n5C+TXJHkjp51AADD6hpAkrwoyadba/90qu3TnWsAAAbW+y2Yn05yrKr+a1XdWlXrVfXczjUAAAPr\nHUAenuT5ST6Z5ElJfivJa6rqWZ3rAAAG1PstmAuSfLS19tLJ9p9U1Q8meV6SN3SuBQAYSO8AckuS\nT2xrGyX5R6c6aGVlJQsLCye1LS8vZ3l5ebbVAcA5aG1tLWtraye1bW5uDlTN7vQOIB9Mcmhb2/cn\nuflUB62urmZxcXGvagKAc9pOL8rX19eztDS/V7nofQ7IapIfqaoXV9UjquoZSX4hyXWd6wAABtQ1\ngLTW/jjJzyZZTvKnSX4lyQtba2unPBAAOK/0fgsmrbXfT/L7vfsFAOaHe8EAAN0JIABAdwIIANCd\nAAIAdCeAAADdCSAAQHcCCADQnQACAHQngAAA3QkgAEB3AggA0J0AAgB0J4AAAN0JIABAdwIIANCd\nAAIAdCeAAADdCSAAQHcCCADQnQACAHQngAAA3QkgAEB3AggA0J0AAgB0J4AAAN0JIABAdwIIANCd\nAAIAdCeAAADdCSAAQHcCCADQnQACAHQngAAA3Q0aQKrq31bV8apaHbIOAKCvwQJIVV2V5J8luTFJ\nG6oOAKC/QQJIVf3NJEeTPDfJHUPUAAAMZ6gVkOuS/M/W2nuS1EA1AAADOdC7w6r6+SRXJrlq0uTt\nFwDYZ7oGkKp6cJL/kOQJrbWvnWjOHK6CbG1tZTQaDVrDoUOHcvDgwUFrAIC90HsFZCnJA5KsV30z\nc9wnyY9V1TVJ7tdau8eKyMrKShYWFk5qW15ezvLy8p4VOhqNsrS0tGfPvxvHjh3L4uLioDUAMP/W\n1taytrZ2Utvm5uZA1exO7wDy7iQ/OLVdSV6XZCPJtTuFjyRZXV0d8D/io0kOd+5zI8mRzn0CcK7a\n6UX5+vr64C+kT6VrAGmt3ZXkE9NtVbWV5EuttU/sfNTQDiexCgEAszQPV0JtcSIqAOwr3T8Fs11r\n7fFD1wAA9DUPKyAAwD4jgAAA3QkgAEB3AggA0J0AAgB0J4AAAN0JIABAdwIIANCdAAIAdCeAAADd\nCSAAQHcCCADQnQACAHQngAAA3QkgAEB3AggA0N2BoQsA4Py3tbWV0Wg0SN8bGxuD9MupCSAA7LnR\naJSlpaWhy2COCCAA9PO0JJd27vOmJO/t3CenJYAA0M+lSR7Uuc/bOvfHrjgJFQDoTgABALoTQACA\n7gQQAKA7AQQA6E4AAQC6E0AAgO4EEACgOwEEAOhOAAEAuhNAAIDuBBAAoDsBBADoTgABALrrHkCq\n6sVV9bGqurOqbq2q/1ZV39+7DgBgOEOsgFyd5LVJHpPkiUkuTPKuqjo4QC0AwAAO9O6wtfYT09tV\n9U+SfDHJYpIP9K4HAOhvHs4Buf/k65cGrQIA6Kb7Csi0qrogyauTfKC19okha4H96atJko2Nje49\nD9Hnfre1tZXRaDRI337fbDdoAElyXZIfSPL3TrXTyspKFhYWTmpbXl7O8vLyHpYG+8HNSZIjR44M\nWwZdjEajLC0tDV0Ge2BtbS1ra2sntW1ubg5Uze4MFkCq6jeS/GSSq1trt5xq39XV1SwuLvYpDPaj\npyW5tHOfNyV5b+c+mTia5HDnPt+e5N917nP/2OlF+fr6+lwHzu4BpKoq40/BPDXJ41prn+5dA7DN\npUke1LnP2zr3x5TDGZ/335O3YDjZECsg1yVZzjiAfKWqLp+0f7m1dvcA9QAAnQ3xKZjnJbkkyfuS\n3DL15+cGqAUAGMAQ1wGZh4/+AgADEgYAgO4EEACgOwEEAOhOAAEAuhNAAIDuBBAAoDsBBADoTgAB\nALoTQACA7gQQAKA7AQQA6E4AAQC6E0AAgO4EEACgOwEEAOjuwNAFsJOvJkk2Nja69zxEnwDsPwLI\nXLo5SXLkyJFhywCAPSKAzLOnJbm0c583JXlv5z4B2HcEkHl2aZIHde7zts79AbAvOQkVAOhOAAEA\nuhNAAIDuBBAAoDsBBADoTgABALoTQACA7gQQAKA7AQQA6E4AAQC6E0AAgO4EEACgOwEEAOhOADkf\n/enQBZyb1tbWhi7h3GOunRVz7SyYa+edQQJIVV1TVTdX1Ver6sNVddUQdZy3/EU9K/5TOAvm2lkx\n186CuXbe6R5AqurpSX49ycuSPCrJnyR5Z1U9oHctAMAwhlgB+aUkv9tau761NkryvCRbSZ4zQC0A\nwAC6BpCqum+SxSTvPtHWWmuT7cf2rAUAGM6Bzv1dmuQ+SW7d1v7FJId22P+iJNnY2Njjsu7pW32+\nPUnv/j84/nJTktvO4vA7k9x4ll1/ZvxliJ/6U5OvQ/y+k2RzczPr6+vd+zXXzLVezLX9Ndem+ryo\ne+e7UOMFiE6dVT0oyV8keWxr7SNT7a9McnVr7Ue27f+MJG/sViAAnH+e2Vp709BFbNd7BeS2JN9I\nctm29suSfH6H/d+Z5JlJbk5y955WBgDnl4uSPDTj/0vnTtcVkCSpqg8n+Whr7QWT7QsyXiB7TWvt\nlV2LAQAG0XsFJEleleT6qvrjJB9L8otJ/kaS1w1QCwAwgO4BpLX25sk1P16R5PIkH0/ylNbaX/au\nBQAYRve3YAAA3AsGAOhOAAEAutt1AKmqq6vqbVX1uao6XlVPnXrsQFVdW1U3VtVdk32ur6rv2sXz\n/nBV/dHkxnSfqapf3mGfx1XVelXdXVU3VdWzd/G8F1XVdVV1W1X9v6p6S1U9cNs+31lVb6yqzaq6\no6p+r6ou3u2Y7Nbpbr5XVa+oqluqaquq/qCqHrGL5zxvx81cO3vm2pkx186euXZmzLUdtNZ29SfJ\nUzI+cfRnkhxP8tNTjy0keVeSf5zkiiSPSfLhJB87zXNekuQLSd6Q5HCSpyf5SpJfmNrnYZO2f5/k\nkUmuSfL1JE86zXP/VpJPJ3lcxpd//19JPrBtn3ckWU9yVZIfTfJ/krxxt2Oyy3F7esbXMHl2xld7\n/Z0kX0rygMnjL0pyR5KfSvJDSd6a5P8mud9+HTdzzVwz1+Z3zMw1c21WY3a2A3nS4N3LPn93st/3\nnGKf52d8cbIDU22/lmRjavvaJDduO24tyTtO8bwLSf4qydOm2h45qecxk+3Dk+3FqX2enPGF0i6f\n4aT7SMbXODmxXRlfDfZFk+3PJ/mlbRPqq0mevp/HzVwz18y1+R0zc81cm8WY7eU5IPdP0pJ8+URD\nVb2+qt47tc9jk7y/tfbXU23vSvLIqlqY2ufdOdm7MnXzusny0vGqesikaSnJhTn5pnefzPiCZycu\n9/7YJF9urU3fkOEPMxngM/lB702d5uZ7VfWwjK8CO/34nRn/5Z7++fbVuJ0Fc81c68VcM9d6Oe/n\n2p4EkKq6KOPU9abW2l1TD92S8ZLOCZfnnjemu3XqsWQ8kXfa55Kqut9k+ytJRhkvK5049muTSb/9\nuMun9vni9IOTX+KXpvb5dp3q5nuXT/Wz0883XcN+G7ddM9e+yVzbY+baN5lre2y/zLWZX4isqi5M\n8uaMk9vztxX3km27t1n02Vr7WJIfmMVzzYnKOEUmMW73xlybCXNtF8y1mTDXdmE/zbWZroBMDdyD\nkzxxW3LbyRdyz6R02dRjp9rnztbaX53iee9bVZfscNz0824/o/dAku+c2ufbdbqb731havve6tzJ\n+T5up2Wu3YO5tkfMtXsw1/bIfptrMwsgUwP3fUme0Fq7YxeHfSjJ1ZOiT3hiklFrbXNqn3+w7bgn\nZnxG7r05lvFS0hOm6ntkkodMnu/E896/qhanjvvxjMfkI7uo/bRaa1+b1DJdxwUZ/zwfaq19KuNf\n1PTjlyR59FSdOzmvx+10zLV7Mtf2hrl2T+ba3tiXc203Z6pOzm69OMmVkz/HM76J3JUZJ7UDSf57\nxieo/HC+9T7g5Uku3HZ27vVT25dknJivT/K3M/4I0V1Jnju1z0Mnbddm/HGvfzEZmCdO7fPojN+/\netBU228muTnjjxAtZeePEL19MtDTHyE6utsx2eW4/VzGZ38/K+Ozhn8nye351sfV/k3G75lNf1zt\nz5Pcd7+Om7lmrplr8ztm5pq5NqsxO5PBe9xk0I5nvPx24vv/lOR7d2g/sX311HO8Lsl7tj3vDyV5\nf8aT+TNJfnmHvv9+xp81vjvJTUmetUNt30jykKm2+yX5jYz/UtyV5C1JHrjtuO9I8sYkd2Z8pvHv\nJTk4y7+ok36umfwi7844NV617fGXTybRVzM+O/kR2x7fV+Nmrplr5tr8jpm5Zq7NaszcjA4A6M69\nYACA7gQQAKA7AQQA6E4AAQC6E0AAgO4EEACgOwEEAOhOAAEAuhNAAIDuBBAAoDsBBADo7v8DZdDO\nSx7gAskAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f43b1badc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import date2num\n",
    "import datetime\n",
    "\n",
    "x = [datetime.datetime(2011, 1, 4, 0, 0),\n",
    "     datetime.datetime(2011, 1, 5, 0, 0),\n",
    "     datetime.datetime(2011, 1, 6, 0, 0)]\n",
    "x = date2num(x)\n",
    "\n",
    "y = [4, 9, 2]\n",
    "z=[1,2,3]\n",
    "k=[11,12,13]\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "ax.bar(x-0.2, y,width=0.2,color='b',align='center')\n",
    "ax.bar(x, z,width=0.2,color='g',align='center')\n",
    "ax.bar(x+0.2, k,width=0.2,color='r',align='center')\n",
    "ax.xaxis_date()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg4AAAFkCAYAAABIPLOYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuRkcJElSbv8PTeTdRaWvTBEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4399dac810>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "N = 3\n",
    "ind = np.arange(N)  # the x locations for the groups\n",
    "width = 0.27       # the width of the bars\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "yvals = [4, 9, 2]\n",
    "rects1 = ax.bar(ind, yvals, width, color='r')\n",
    "zvals = [1,2,3]\n",
    "rects2 = ax.bar(ind+width, zvals, width, color='g')\n",
    "kvals = [11,12,13]\n",
    "rects3 = ax.bar(ind+width*2, kvals, width, color='b')\n",
    "\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_xticks(ind+width)\n",
    "ax.set_xticklabels( ('WikiQA', 'Trec TRAIN', 'Trec TRAIN ALL') )\n",
    "ax.legend( (rects1[0], rects2[0], rects3[0]), ('y', 'z', 'k') )\n",
    "\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        h = rect.get_height()\n",
    "        ax.text(rect.get_x()+rect.get_width()/2., 1.05*h, '%d'%int(h),\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "autolabel(rects3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 ARM",
   "language": "python",
   "name": "py2-arm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
