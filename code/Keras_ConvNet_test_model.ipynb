{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 5103)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import QAData\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import PassageRetrieval as pr\n",
    "from json2html import *\n",
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "import pylab as plt\n",
    "import nlp_utils\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from json_utils import JSONConnector\n",
    "from QAData import DataSetFactory\n",
    "import models\n",
    "from passrtv_models import PassageRetrievalModel\n",
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "from keras.layers import Convolution1D, Convolution2D\n",
    "from keras.layers import Input, Embedding, merge, Flatten, SimpleRNN\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalMaxPooling2D, Activation, Input, Dense, merge, Dropout, LSTM\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution1D, Convolution2D, GlobalMaxPooling2D, Activation, Input, Dense, merge, Dropout\n",
    "from keras.layers import Flatten, SimpleRNN\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.callbacks import Callback\n",
    "from itertools import groupby\n",
    "import sys\n",
    "import pickle\n",
    "import nlp_utils\n",
    "import numpy as np\n",
    "import threading\n",
    "import models as models\n",
    "from models import threadsafe_generator\n",
    "from scipy import spatial\n",
    "import nltk\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "  \"expriment_id\" : \"keras_convnet_$runid\",\n",
    "  \"dataset_partitions\" : [\"train\",\"validate\",\"test\"],\n",
    "  \"dataset\": \"TrecDataSet\",\n",
    "  \"ground_truth_file\": \"/home/aerossom/passage-retrieval/experiments/gold-jakana-test.rank\",\n",
    "  \"model\" : \"KerasConvNetModel_5\",\n",
    "  \"modeldes\" : \"Convolutional NN with 1d input tensor cosine sim input matrix element wise multiplied by salience matrix\",\n",
    "  \"out_folder\": \"/home/aerossom/passage-retrieval/experiments/\",\n",
    "  \"working_folder\": \"/home/aerossom/passage-retrieval/experiments/working_files/\",\n",
    "  \"trec_eval_path\" : \"/home/aerossom/trec_eval.9.0/trec_eval\",\n",
    "  \"out_rank_file\" : \"keras_convnet_matrixsim_$runid.rank\",\n",
    "  \"word2vect_path\" : \"/home/aerossom/datasets/word2vect/GoogleNews-vectors-negative300.bin\",\n",
    "  \"preprocess_steps\" : [],\n",
    "  \"method_params\" : {\n",
    "                      \"optimizer\": \"rmsprop\",\n",
    "                      \"loss\":\"mean_squared_error\",\n",
    "                      \"monitor\": \"val_loss\",\n",
    "                      \"verbose\" : 1,\n",
    "                      \"positive_rate\": 0.5,\n",
    "            \t\t      \"epochs\": 500,\n",
    "            \t\t      \"batch_size\": 256,\n",
    "            \t\t      \"validation_size\" : 64,\n",
    "            \t\t      \"max_words\" : 40,\n",
    "            \t\t      \"patience\": 50,\n",
    "                      \"convolution_2d\" : {\n",
    "                        \"nb_filter\": 64,\n",
    "                        \"nb_row\": 3,\n",
    "                        \"nb_col\": 3,\n",
    "                        \"subsample\": 1,\n",
    "                        \"border_mode\" : \"valid\",\n",
    "                        \"activation\" : \"relu\"\n",
    "                      },\n",
    "                      \"activation_2nd_Layer\" : \"relu\",\n",
    "                      \"dense_4th_Layer\" : 30,\n",
    "                      \"dropout\" : 0.1,\n",
    "                      \"dense_6th_layer\" : 1,\n",
    "                      \"end_layer_activation\" : \"sigmoid\"\n",
    "\t\t    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2v_path = '/home/aerossom/datasets/word2vect/GoogleNews-vectors-negative300.bin'\n",
    "w2v_util = nlp_utils.Word2vectUtils(w2v_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ds = DataSetFactory.loadDataSet('TrecDataSet')\n",
    "#ds = DataSetFactory.loadDataSet('TrecDataSet_TrainAll')\n",
    "ds = DataSetFactory.loadDataSet('WikiQADataSet')\n",
    "\n",
    "qa_pair = {}\n",
    "qa_pair['train'] = ds.build_qa_pairs(ds.questions['train'])\n",
    "qa_pair['validate'] = ds.build_qa_pairs(ds.questions['validate'])\n",
    "qa_pair['test'] = ds.build_qa_pairs(ds.questions['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def avg_precision(y_true, y_pred):\n",
    "    zipped = zip(y_true, y_pred)\n",
    "    zipped.sort(key=lambda x:x[1],reverse=True)\n",
    "    np_y_true, np_y_pred = zip(*zipped)\n",
    "    k_list = [i for i in range(len(np_y_true)) if int(np_y_true[i])==1]\n",
    "    score = 0.\n",
    "    r = np.sum(np_y_true).astype(np.int64)\n",
    "    for k in k_list:\n",
    "        Yk = np.sum(np_y_true[:k+1])\n",
    "        score += Yk/float(k+1)\n",
    "    if r==0:\n",
    "        return 0\n",
    "    score/=(r)\n",
    "    return score\n",
    "\n",
    "\"\"\"\n",
    "https://en.wikipedia.org/wiki/Mean_reciprocal_rank\n",
    "\"\"\"\n",
    "def reciprocal_rank(y_true, y_pred):\n",
    "    zipped = zip(y_true, y_pred)\n",
    "    zipped.sort(key=lambda x:x[1],reverse=True)\n",
    "    count_r = 1.0\n",
    "    rr_score = 0.0\n",
    "    for y_t,y_p in zipped:\n",
    "        if(y_t!=1):\n",
    "            count_r += 1\n",
    "        else:\n",
    "            rr_score = 1.0/count_r\n",
    "            break\n",
    "    if count_r-1==len(y_true):\n",
    "        rr_score = 0.0\n",
    "    return rr_score\n",
    "\n",
    "class MAPCallback(Callback):\n",
    "    \n",
    "    def __init__(self, validation_data, max_words, proc_funct, filepath, min_delta=0, patience=50, verbose=1, save_best_only=True, save_weights_only=True, period=1):\n",
    "        super(MAPCallback, self).__init__()\n",
    "        self.val_ds = validation_data\n",
    "        self.max_words = max_words\n",
    "        self.proc_fuction = proc_funct\n",
    "        self.map_score = []\n",
    "        self.mrr_score = []\n",
    "        self.min_delta = min_delta\n",
    "        #maximize the map\n",
    "        self.monitor_op = np.greater\n",
    "        self.patience = patience\n",
    "        self.period = period\n",
    "        self.verbose = verbose\n",
    "        self.save_best_only = save_best_only\n",
    "        self.save_weights_only = save_weights_only\n",
    "        self.epochs_since_last_save = 0\n",
    "        self.filepath = filepath\n",
    "        self.min_delta *= -1\n",
    "        self.stopped_epoch = 0\n",
    "    \n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.wait = 0  # Allow instances to be re-used\n",
    "        self.best = np.Inf if self.monitor_op == np.less else -np.Inf\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current_map, current_mrr = self.calculate_map_mrr()\n",
    "        self.save_model(epoch, logs, current_map)\n",
    "        logging.info(\"MAP evaluation - epoch: {:d} - score: {:.6f}\".format(epoch, current_map))\n",
    "        logging.info(\"MRR evaluation - epoch: {:d} - score: {:.6f}\".format(epoch, current_mrr))\n",
    "        if current_map is None:\n",
    "            warnings.warn('MAP Early stopping requires %s available!' %\n",
    "                          (self.monitor), RuntimeWarning)\n",
    "\n",
    "        if self.monitor_op(current_map - self.min_delta, self.best):\n",
    "            self.best = current_map\n",
    "            self.wait = 0\n",
    "        else:\n",
    "            if self.wait >= self.patience:\n",
    "                self.stopped_epoch = epoch\n",
    "                self.model.stop_training = True\n",
    "            self.wait += 1\n",
    "\n",
    "    def on_train_end(self, logs=None):\n",
    "        if self.stopped_epoch > 0 and self.verbose > 0:\n",
    "        #    print('Epoch %05d: MAP early stopping' % (self.stopped_epoch))\n",
    "            logging.info(\"MAP early stopping Epoch {:d} evaluation - MAP: {:.6f} \".format(self.stopped_epoch,self.best))\n",
    "    \n",
    "    def save_model(self, epoch, logs, cmap):\n",
    "        logs = logs or {}\n",
    "        self.epochs_since_last_save += 1\n",
    "        if self.epochs_since_last_save >= self.period:\n",
    "            self.epochs_since_last_save = 0\n",
    "            filepath = self.filepath.format(epoch=epoch, **logs)\n",
    "            if self.save_best_only:\n",
    "                current = cmap\n",
    "                if current is None:\n",
    "                    warnings.warn('Can save best model only with %s available, '\n",
    "                                  'skipping.' % (' MAP '), RuntimeWarning)\n",
    "                else:\n",
    "                    if self.monitor_op(current, self.best):\n",
    "                        if self.verbose > 0:\n",
    "                            print('Epoch %05d: %s improved from %0.5f to %0.5f,'\n",
    "                                  ' saving model to %s'\n",
    "                                  % (epoch, ' MAP ', self.best,\n",
    "                                     current, filepath))\n",
    "                        self.best = current\n",
    "                        if self.save_weights_only:\n",
    "                            self.model.save_weights(filepath, overwrite=True)\n",
    "                        else:\n",
    "                            self.model.save(filepath, overwrite=True)\n",
    "                    else:\n",
    "                        if self.verbose > 0:\n",
    "                            print('Epoch %05d: %s did not improve' %\n",
    "                                  (epoch, ' MAP '))\n",
    "            else:\n",
    "                if self.verbose > 0:\n",
    "                    print('Epoch %05d: saving model to %s' % (epoch, filepath))\n",
    "                if self.save_weights_only:\n",
    "                    self.model.save_weights(filepath, overwrite=True)\n",
    "                else:\n",
    "                    self.model.save(filepath, overwrite=True)\n",
    "\n",
    "    def calculate_map_mrr(self):\n",
    "        y_true = []\n",
    "        y_pred = []\n",
    "        avg_p = []\n",
    "        rr_list = []\n",
    "        num_groups = 0\n",
    "        for key, group in groupby(self.val_ds, lambda x: x.qi):\n",
    "            samples = []\n",
    "            is_any_true = False\n",
    "            for q_g in group:\n",
    "                samples.append(q_g)\n",
    "                if q_g.l == 1:\n",
    "                    is_any_true = True\n",
    "            #Just take the 1/3 of the dataset randomly\n",
    "            if random.uniform(0, 10) > 8:\n",
    "                is_any_true = False\n",
    "            if is_any_true:\n",
    "                x, y_true = self.proc_fuction(samples,max_terms=self.max_words)\n",
    "                y_pred = self.model.predict_proba(x, verbose=0)\n",
    "                avg_p_score = avg_precision(y_true, y_pred)\n",
    "                avg_p.append( avg_p_score )\n",
    "                rr_score = reciprocal_rank(y_true, y_pred)\n",
    "                rr_list.append( rr_score )\n",
    "                #print y_true\n",
    "                #print y_pred\n",
    "                #print 'avg_prec = ', avg_p_score, ', rr = ', rr_score\n",
    "                num_groups += 1\n",
    "        cmap_score = sum(avg_p)/num_groups\n",
    "        cmrr_score = sum(rr_list)/num_groups\n",
    "        self.map_score.append(cmap_score)\n",
    "        self.mrr_score.append(cmrr_score)\n",
    "        #print 'map = ', cmap_score, ', mrr = ', cmrr_score\n",
    "        return cmap_score, cmrr_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Convolutional NN with 1d input tensor cosine sim input matrix element wise multiplied by salience matrix\n",
    "\"\"\"\n",
    "class KerasConvNetModel_5(models.PassageRetrievalModel):\n",
    "\n",
    "    def __init__(self,init_params):\n",
    "        super(KerasConvNetModel_5, self).__init__('KerasConvNetModel_5', init_params['runid'])\n",
    "        self.w2vutil = init_params['w2v']\n",
    "        self.w2v = self.w2vutil.getWord2VectModel()\n",
    "        self.params = init_params['params']\n",
    "        self.max_words = self.params['method_params']['max_words']\n",
    "        self.positive_rate = self.params['method_params']['positive_rate']\n",
    "        self.prep_step = [ str(step) for step in init_params['params']['preprocess_steps'] ]\n",
    "\n",
    "    def getSalienceScore(self, qv, av, maxterms=40):\n",
    "        score = 0\n",
    "        #print qv, av\n",
    "        imp_postag = set(['WRB','VB', 'VBD', 'VBG', 'VBN', 'VBP','VBZ', 'WDT', 'WP', 'WRB', 'NN', 'NNS', 'NNP', 'NNPS', 'MD'])\n",
    "        pw1 = nltk.pos_tag(qv)\n",
    "        pw2 = nltk.pos_tag(av)\n",
    "        if len(pw1)>maxterms:\n",
    "            pw1 = pw1[0:maxterms]\n",
    "        if len(pw2)>maxterms:\n",
    "            pw2 = pw2[0:maxterms]\n",
    "        w1_m = np.zeros((maxterms,maxterms))\n",
    "        w2_m = np.zeros((maxterms,maxterms))\n",
    "        pw1_l = [len(set([w1[1]]).intersection(imp_postag)) for w1 in pw1]\n",
    "        w1_m[:,0:len(pw1_l)]=pw1_l\n",
    "        pw2_l = [len(set([w2[1]]).intersection(imp_postag)) for w2 in pw2]\n",
    "        w2_m[:,0:len(pw2_l)]=pw2_l\n",
    "        out_m = (w1_m + w2_m.T)/2\n",
    "        #print pw1_l, pw2_l, pw1\n",
    "        return out_m[0:maxterms,0:maxterms]\n",
    "\n",
    "    def buildCosineSimMatrix(self, questions_answer_pairs, max_terms=20):\n",
    "        #Construct Question Answer Matrix Pairs\n",
    "        x = []\n",
    "        y = []\n",
    "        for pair in questions_answer_pairs:\n",
    "            q_list = nlp_utils.data_preprocess(pair.q,self.prep_step)\n",
    "            a_list = []\n",
    "            q_vect = self.w2vutil.transform2Word2Vect(q_list)\n",
    "            cos_matrix = []\n",
    "            sal_matrix = []\n",
    "            for i, q_i in enumerate(q_vect):\n",
    "                if i==max_terms:\n",
    "                    break\n",
    "                sim_qi_a = []\n",
    "                a_list = nlp_utils.data_preprocess(pair.a,self.prep_step)\n",
    "                a_vect = self.w2vutil.transform2Word2Vect(a_list)\n",
    "                for k, a_k in enumerate(a_vect):\n",
    "                    if k==max_terms:\n",
    "                        break\n",
    "                    sim_qi_a += [spatial.distance.cosine(q_i, a_k)]\n",
    "                cos_matrix += [sim_qi_a]\n",
    "            sal_matrix = self.getSalienceScore(q_list,a_list,max_terms)\n",
    "            cos_matrix = np.array(cos_matrix)\n",
    "            #sal_matrix = np.array(sal_matrix)\n",
    "            shape_cos_matrix = cos_matrix.shape\n",
    "            #print 'shapes: ', sal_matrix.shape, cos_matrix.shape\n",
    "            cos_matrix = np.pad(cos_matrix, ((0,max_terms-shape_cos_matrix[0]),(0,max_terms-shape_cos_matrix[1])), \\\n",
    "                                mode='constant', constant_values=2)\n",
    "            #sal_matrix = np.pad(sal_matrix, ((0,max_terms-shape_cos_matrix[0]),(0,max_terms-shape_cos_matrix[1])), mode='constant')\n",
    "            if np.isnan(cos_matrix).any():\n",
    "                print 'ERROR IS NAN: ',pair\n",
    "            #x.append( np.expand_dims(np.multiply(cos_matrix, sal_matrix),0) )\n",
    "            x.append( np.expand_dims(cos_matrix,0) )\n",
    "            y.append( pair.l )\n",
    "        return np.array(x), np.array(y)\n",
    "\n",
    "    def load_model(self):\n",
    "        self.model = Sequential()\n",
    "        mp = self.params['method_params']\n",
    "        self.model.add(Convolution2D(\n",
    "            nb_filter=mp['convolution_2d']['nb_filter'],\n",
    "            nb_row=mp['convolution_2d']['nb_row'],\n",
    "            nb_col=mp['convolution_2d']['nb_col'],\n",
    "            subsample=(mp['convolution_2d']['subsample'], mp['convolution_2d']['subsample']),\n",
    "            border_mode=mp['convolution_2d']['border_mode'],\n",
    "            activation=mp['convolution_2d']['activation'],\n",
    "            input_shape=(1, self.max_words, self.max_words)))\n",
    "        self.model.add(Activation(mp['activation_2nd_Layer']))\n",
    "        self.model.add(GlobalMaxPooling2D())\n",
    "        self.model.add(Dense(mp['dense_4th_Layer']))\n",
    "        self.model.add(Dropout(mp['dropout']))\n",
    "        self.model.add(Dense(mp['dense_6th_layer']))\n",
    "        self.model.add(Activation(mp['end_layer_activation']))\n",
    "        return self.model\n",
    "\n",
    "    @threadsafe_generator\n",
    "    def generateXYBatches(self, ds, dataset, num_samples, positive_rate=0.5):\n",
    "        samples = ds.get_random_samples(dataset, num_samples, self.positive_rate)\n",
    "        while 1:\n",
    "            x, y = self.buildCosineSimMatrix(samples,max_terms=self.max_words)\n",
    "            yield ( x, y )\n",
    "\n",
    "    def train(self, ds, qa_pair):\n",
    "        self.model = self.load_model()\n",
    "        self.best_params=self.params['working_folder']+self.params['expriment_id'].replace('$runid',self.runid)+\"_best.hdf5\"\n",
    "        #if want to load the best weights in other training\n",
    "        #self.model.load_weights(self.best_params)\n",
    "        #MAP CallBack\n",
    "        map_callback = MAPCallback(qa_pair['validate'], self.max_words, self.buildCosineSimMatrix, self.best_params)\n",
    "        # checkpoints\n",
    "        #output the model weights each time an improvement is observed during training\n",
    "        #checkpoint = ModelCheckpoint(self.best_params, monitor=self.params['method_params']['monitor'], verbose=self.params['method_params']['verbose'], save_best_only=True, mode='auto')\n",
    "        #stops if the model is not learning at any point\n",
    "        #earlyStopping= EarlyStopping(monitor=self.params['method_params']['monitor'], patience=self.params['method_params']['patience'], verbose=self.params['method_params']['verbose'], mode='auto')\n",
    "        \n",
    "        epochs_number = self.params['method_params']['epochs']\n",
    "        batch_size = self.params['method_params']['batch_size']\n",
    "        validation_size = self.params['method_params']['validation_size']\n",
    "\n",
    "        self.model.compile(loss='mean_squared_error',\n",
    "                      optimizer='rmsprop',\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        history = self.model.fit_generator(\n",
    "                    self.generateXYBatches(ds, qa_pair['train'], batch_size, positive_rate=self.positive_rate),\n",
    "                    samples_per_epoch=batch_size,\n",
    "                    validation_data=self.generateXYBatches(ds, qa_pair['validate'], validation_size, positive_rate=self.positive_rate),\n",
    "                    nb_val_samples=validation_size,\n",
    "                    nb_epoch=epochs_number,\n",
    "                    callbacks=[map_callback]\n",
    "                    #callbacks=[checkpoint, earlyStopping, map_callback]\n",
    "                    )\n",
    "        \n",
    "        #Add MAP and MRR to history\n",
    "        history.history['map'] = map_callback.map_score\n",
    "        history.history['mrr'] = map_callback.mrr_score\n",
    "        #Save history object in pickel\n",
    "        self.save_history( self.best_params.replace('_best.hdf5','_history.pkl'), history )\n",
    "        return history\n",
    "    \n",
    "    def save_history(self,out_file, history):\n",
    "        with open(out_file, 'wb') as output:\n",
    "            pickle.dump(history.history, output, pickle.HIGHEST_PROTOCOL)\n",
    "        \"\"\"\n",
    "        To Open \n",
    "            with open('in_file.pkl', 'rb') as input:\n",
    "                history = pickle.load(input)\n",
    "        \"\"\"\n",
    "\n",
    "    def test(self, ds, qa_pairs):\n",
    "        #reload best weights\n",
    "        self.model.load_weights(self.best_params)\n",
    "        #Construct Test dataset\n",
    "        test_qxa, test_l = self.buildCosineSimMatrix(qa_pairs, max_terms=self.max_words)\n",
    "        predictions = self.model.predict(np.array(test_qxa))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "in_file = '/home/aerossom/passage-retrieval/experiments/working_files/keras_convnet_test_run_history.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(in_file, 'rb') as input:\n",
    "    history = pickle.load(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_params = {\"w2v\": w2v_util, \"runid\":'test_run',  \"params\":params }\n",
    "k_model = KerasConvNetModel_5(model_params)\n",
    "#history = k_model.train(ds, qa_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First predictions\n",
    "k_model = KerasConvNetModel_5(model_params)\n",
    "test_qxa, test_l = k_model.buildCosineSimMatrix(qa_pair['test'], max_terms=40)\n",
    "train_qxa, train_l = k_model.buildCosineSimMatrix(qa_pair['train'], max_terms=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how are glacier caves formed ? A partly submerged glacier cave on Perito Moreno Glacier .\n"
     ]
    }
   ],
   "source": [
    "print qa_pair['train'][0].q, qa_pair['train'][0].a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1.   0.9  0.9  1.   0.9  0.8  1.1  0.9  1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 0.9  0.9  1.   1.   0.9  0.9  1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   0.9  0.7  0.   0.6  1.   1.   0.9  0.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   0.9  0.8  0.6  0.2  1.   1.   0.9  0.6  1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   0.9  0.9  1.   0.9  1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]\n",
      "  [ 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
      "    1.   1.   1.   1.   1.   1.   1.   1.   1.   1. ]]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(precision=1)\n",
    "np.set_printoptions(threshold='nan')\n",
    "np.set_printoptions(suppress=True)\n",
    "#print test_qxa[0]\n",
    "print np.array_str(train_qxa[0], precision=1, suppress_small=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87770495563745499"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial.distance.cosine(w2v_util.w2v_model['glacier'], w2v_util.w2v_model['oil'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "model = models.load_model('/home/aerossom/passage-retrieval/experiments/working_files/keras_convnet_1492099016_best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nlp_utils import avg_precision\n",
    "from nlp_utils import reciprocal_rank\n",
    "#Make the first preditions\n",
    "first_predictions = model.predict(np.array(test_qxa))\n",
    "rank_file_1 = 'experiments/rankfile_0.rank'\n",
    "idx_pred = 0\n",
    "rank_text = ''\n",
    "for key,group in groupby(qa_pair['test'], lambda x: x.qi):\n",
    "    for i, qp in enumerate(group):\n",
    "        rank_text += str(qp.qi) + ' 0 ' + str(qp.ai) + ' 0 ' + str(first_predictions[idx_pred][0]) + ' 0\\n'\n",
    "        idx_pred += 1\n",
    "with open(rank_file_1, 'wb') as text_file:\n",
    "    text_file.write(rank_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runid                 \tall\t0\r\n",
      "num_q                 \tall\t237\r\n",
      "num_ret               \tall\t2341\r\n",
      "num_rel               \tall\t283\r\n",
      "num_rel_ret           \tall\t283\r\n",
      "map                   \tall\t0.5940\r\n",
      "gm_map                \tall\t0.4601\r\n",
      "Rprec                 \tall\t0.4339\r\n",
      "bpref                 \tall\t0.4259\r\n",
      "recip_rank            \tall\t0.6047\r\n",
      "iprec_at_recall_0.00  \tall\t0.6096\r\n",
      "iprec_at_recall_0.10  \tall\t0.6096\r\n",
      "iprec_at_recall_0.20  \tall\t0.6096\r\n",
      "iprec_at_recall_0.30  \tall\t0.6035\r\n",
      "iprec_at_recall_0.40  \tall\t0.6014\r\n",
      "iprec_at_recall_0.50  \tall\t0.6014\r\n",
      "iprec_at_recall_0.60  \tall\t0.5902\r\n",
      "iprec_at_recall_0.70  \tall\t0.5902\r\n",
      "iprec_at_recall_0.80  \tall\t0.5863\r\n",
      "iprec_at_recall_0.90  \tall\t0.5863\r\n",
      "iprec_at_recall_1.00  \tall\t0.5863\r\n",
      "P_5                   \tall\t0.1890\r\n",
      "P_10                  \tall\t0.1118\r\n",
      "P_15                  \tall\t0.0785\r\n",
      "P_20                  \tall\t0.0595\r\n",
      "P_30                  \tall\t0.0398\r\n",
      "P_100                 \tall\t0.0119\r\n",
      "P_200                 \tall\t0.0060\r\n",
      "P_500                 \tall\t0.0024\r\n",
      "P_1000                \tall\t0.0012\r\n"
     ]
    }
   ],
   "source": [
    "!/home/aerossom/trec_eval.9.0/trec_eval -c /home/aerossom/datasets/WikiQACorpus/WikiQA-test-filtered.ref \\\n",
    "experiments/rankfile_0.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trec_eval: No queries with both results and relevance info\r\n"
     ]
    }
   ],
   "source": [
    "!/home/aerossom/trec_eval.9.0/trec_eval -c /home/aerossom/passage-retrieval/experiments/gold-jakana-test2.rank \\\n",
    "experiments/rankfile_0.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  l= 1 map_1:  1.0  map_2:  1.0\n",
      "2  l= 0 map_1:  0  map_2:  0\n",
      "3  l= 1 map_1:  0.25  map_2:  0.5\n",
      "4  l= 1 map_1:  1.0  map_2:  1.0\n",
      "5  l= 4 map_1:  0.15499465812  map_2:  0.326923076923\n",
      "6  l= 0 map_1:  0  map_2:  0\n",
      "7  l= 0 map_1:  0  map_2:  0\n",
      "8  l= 0 map_1:  0  map_2:  0\n",
      "9  l= 0 map_1:  0  map_2:  0\n",
      "10  l= 1 map_1:  0.333333333333  map_2:  0.25\n",
      "11  l= 1 map_1:  1.0  map_2:  1.0\n",
      "12  l= 0 map_1:  0  map_2:  0\n",
      "13  l= 0 map_1:  0  map_2:  0\n",
      "14  l= 0 map_1:  0  map_2:  0\n",
      "15  l= 0 map_1:  0  map_2:  0\n",
      "16  l= 0 map_1:  0  map_2:  0\n",
      "17  l= 0 map_1:  0  map_2:  0\n",
      "18  l= 0 map_1:  0  map_2:  0\n",
      "19  l= 0 map_1:  0  map_2:  0\n",
      "20  l= 2 map_1:  0.7  map_2:  0.833333333333\n",
      "21  l= 1 map_1:  1.0  map_2:  1.0\n",
      "22  l= 1 map_1:  0.25  map_2:  0.111111111111\n",
      "23  l= 0 map_1:  0  map_2:  0\n",
      "24  l= 1 map_1:  0.5  map_2:  0.1\n",
      "25  l= 0 map_1:  0  map_2:  0\n",
      "26  l= 0 map_1:  0  map_2:  0\n",
      "27  l= 2 map_1:  0.22619047619  map_2:  0.22619047619\n",
      "28  l= 1 map_1:  1.0  map_2:  1.0\n",
      "29  l= 1 map_1:  0.5  map_2:  0.2\n",
      "30  l= 2 map_1:  0.392857142857  map_2:  0.375\n",
      "31  l= 0 map_1:  0  map_2:  0\n",
      "32  l= 0 map_1:  0  map_2:  0\n",
      "33  l= 0 map_1:  0  map_2:  0\n",
      "34  l= 0 map_1:  0  map_2:  0\n",
      "35  l= 1 map_1:  0.333333333333  map_2:  0.5\n",
      "36  l= 0 map_1:  0  map_2:  0\n",
      "37  l= 0 map_1:  0  map_2:  0\n",
      "38  l= 0 map_1:  0  map_2:  0\n",
      "39  l= 0 map_1:  0  map_2:  0\n",
      "40  l= 0 map_1:  0  map_2:  0\n",
      "41  l= 0 map_1:  0  map_2:  0\n",
      "42  l= 0 map_1:  0  map_2:  0\n",
      "43  l= 0 map_1:  0  map_2:  0\n",
      "44  l= 2 map_1:  1.0  map_2:  1.0\n",
      "45  l= 0 map_1:  0  map_2:  0\n",
      "46  l= 0 map_1:  0  map_2:  0\n",
      "47  l= 0 map_1:  0  map_2:  0\n",
      "48  l= 0 map_1:  0  map_2:  0\n",
      "49  l= 3 map_1:  1.0  map_2:  1.0\n",
      "50  l= 0 map_1:  0  map_2:  0\n",
      "51  l= 0 map_1:  0  map_2:  0\n",
      "52  l= 1 map_1:  1.0  map_2:  1.0\n",
      "53  l= 0 map_1:  0  map_2:  0\n",
      "54  l= 0 map_1:  0  map_2:  0\n",
      "55  l= 0 map_1:  0  map_2:  0\n",
      "56  l= 0 map_1:  0  map_2:  0\n",
      "57  l= 0 map_1:  0  map_2:  0\n",
      "58  l= 0 map_1:  0  map_2:  0\n",
      "59  l= 0 map_1:  0  map_2:  0\n",
      "60  l= 0 map_1:  0  map_2:  0\n",
      "61  l= 2 map_1:  1.0  map_2:  0.590909090909\n",
      "62  l= 2 map_1:  0.321428571429  map_2:  0.291666666667\n",
      "63  l= 0 map_1:  0  map_2:  0\n",
      "64  l= 1 map_1:  0.5  map_2:  0.333333333333\n",
      "65  l= 0 map_1:  0  map_2:  0\n",
      "66  l= 0 map_1:  0  map_2:  0\n",
      "67  l= 1 map_1:  0.5  map_2:  0.333333333333\n",
      "68  l= 0 map_1:  0  map_2:  0\n",
      "69  l= 1 map_1:  0.5  map_2:  0.5\n",
      "70  l= 0 map_1:  0  map_2:  0\n",
      "71  l= 0 map_1:  0  map_2:  0\n",
      "72  l= 1 map_1:  1.0  map_2:  1.0\n",
      "73  l= 0 map_1:  0  map_2:  0\n",
      "74  l= 2 map_1:  0.583333333333  map_2:  0.583333333333\n",
      "75  l= 0 map_1:  0  map_2:  0\n",
      "76  l= 1 map_1:  1.0  map_2:  1.0\n",
      "77  l= 1 map_1:  0.333333333333  map_2:  0.5\n",
      "78  l= 0 map_1:  0  map_2:  0\n",
      "79  l= 0 map_1:  0  map_2:  0\n",
      "80  l= 1 map_1:  0.5  map_2:  0.5\n",
      "81  l= 1 map_1:  0.2  map_2:  0.333333333333\n",
      "82  l= 0 map_1:  0  map_2:  0\n",
      "83  l= 1 map_1:  0.125  map_2:  0.166666666667\n",
      "84  l= 1 map_1:  0.5  map_2:  0.5\n",
      "85  l= 0 map_1:  0  map_2:  0\n",
      "86  l= 0 map_1:  0  map_2:  0\n",
      "87  l= 0 map_1:  0  map_2:  0\n",
      "88  l= 0 map_1:  0  map_2:  0\n",
      "89  l= 0 map_1:  0  map_2:  0\n",
      "90  l= 0 map_1:  0  map_2:  0\n",
      "91  l= 1 map_1:  1.0  map_2:  1.0\n",
      "92  l= 0 map_1:  0  map_2:  0\n",
      "93  l= 0 map_1:  0  map_2:  0\n",
      "94  l= 0 map_1:  0  map_2:  0\n",
      "95  l= 0 map_1:  0  map_2:  0\n",
      "96  l= 0 map_1:  0  map_2:  0\n",
      "97  l= 1 map_1:  0.5  map_2:  0.333333333333\n",
      "98  l= 0 map_1:  0  map_2:  0\n",
      "99  l= 1 map_1:  0.25  map_2:  0.2\n",
      "100  l= 0 map_1:  0  map_2:  0\n",
      "101  l= 0 map_1:  0  map_2:  0\n",
      "102  l= 0 map_1:  0  map_2:  0\n",
      "103  l= 1 map_1:  1.0  map_2:  1.0\n",
      "104  l= 2 map_1:  0.45  map_2:  0.325\n",
      "105  l= 0 map_1:  0  map_2:  0\n",
      "106  l= 0 map_1:  0  map_2:  0\n",
      "107  l= 0 map_1:  0  map_2:  0\n",
      "108  l= 0 map_1:  0  map_2:  0\n",
      "109  l= 0 map_1:  0  map_2:  0\n",
      "110  l= 0 map_1:  0  map_2:  0\n",
      "111  l= 0 map_1:  0  map_2:  0\n",
      "112  l= 0 map_1:  0  map_2:  0\n",
      "113  l= 0 map_1:  0  map_2:  0\n",
      "114  l= 0 map_1:  0  map_2:  0\n",
      "115  l= 0 map_1:  0  map_2:  0\n",
      "116  l= 0 map_1:  0  map_2:  0\n",
      "117  l= 0 map_1:  0  map_2:  0\n",
      "118  l= 0 map_1:  0  map_2:  0\n",
      "119  l= 1 map_1:  0.333333333333  map_2:  0.5\n",
      "120  l= 1 map_1:  0.5  map_2:  0.5\n",
      "121  l= 1 map_1:  0.5  map_2:  0.5\n",
      "122  l= 1 map_1:  0.2  map_2:  0.2\n",
      "123  l= 0 map_1:  0  map_2:  0\n",
      "124  l= 1 map_1:  1.0  map_2:  1.0\n",
      "125  l= 0 map_1:  0  map_2:  0\n",
      "126  l= 0 map_1:  0  map_2:  0\n",
      "127  l= 1 map_1:  1.0  map_2:  1.0\n",
      "128  l= 1 map_1:  0.166666666667  map_2:  0.166666666667\n",
      "129  l= 1 map_1:  0.5  map_2:  0.5\n",
      "130  l= 0 map_1:  0  map_2:  0\n",
      "131  l= 0 map_1:  0  map_2:  0\n",
      "132  l= 0 map_1:  0  map_2:  0\n",
      "133  l= 1 map_1:  0.0769230769231  map_2:  0.5\n",
      "134  l= 1 map_1:  0.2  map_2:  0.2\n",
      "135  l= 0 map_1:  0  map_2:  0\n",
      "136  l= 1 map_1:  0.5  map_2:  0.5\n",
      "137  l= 3 map_1:  0.916666666667  map_2:  0.805555555556\n",
      "138  l= 1 map_1:  0.2  map_2:  0.5\n",
      "139  l= 0 map_1:  0  map_2:  0\n",
      "140  l= 1 map_1:  0.2  map_2:  0.5\n",
      "141  l= 1 map_1:  1.0  map_2:  1.0\n",
      "142  l= 0 map_1:  0  map_2:  0\n",
      "143  l= 0 map_1:  0  map_2:  0\n",
      "144  l= 0 map_1:  0  map_2:  0\n",
      "145  l= 0 map_1:  0  map_2:  0\n",
      "146  l= 1 map_1:  0.0833333333333  map_2:  0.166666666667\n",
      "147  l= 0 map_1:  0  map_2:  0\n",
      "148  l= 0 map_1:  0  map_2:  0\n",
      "149  l= 0 map_1:  0  map_2:  0\n",
      "150  l= 1 map_1:  1.0  map_2:  1.0\n",
      "151  l= 0 map_1:  0  map_2:  0\n",
      "152  l= 1 map_1:  0.166666666667  map_2:  0.2\n",
      "153  l= 0 map_1:  0  map_2:  0\n",
      "154  l= 2 map_1:  1.0  map_2:  1.0\n",
      "155  l= 0 map_1:  0  map_2:  0\n",
      "156  l= 1 map_1:  0.5  map_2:  0.166666666667\n",
      "157  l= 0 map_1:  0  map_2:  0\n",
      "158  l= 1 map_1:  1.0  map_2:  1.0\n",
      "159  l= 0 map_1:  0  map_2:  0\n",
      "160  l= 1 map_1:  1.0  map_2:  1.0\n",
      "161  l= 0 map_1:  0  map_2:  0\n",
      "162  l= 1 map_1:  0.166666666667  map_2:  0.111111111111\n",
      "163  l= 1 map_1:  1.0  map_2:  1.0\n",
      "164  l= 0 map_1:  0  map_2:  0\n",
      "165  l= 0 map_1:  0  map_2:  0\n",
      "166  l= 0 map_1:  0  map_2:  0\n",
      "167  l= 0 map_1:  0  map_2:  0\n",
      "168  l= 0 map_1:  0  map_2:  0\n",
      "169  l= 1 map_1:  0.5  map_2:  0.5\n",
      "170  l= 0 map_1:  0  map_2:  0\n",
      "171  l= 4 map_1:  0.582142857143  map_2:  0.575\n",
      "172  l= 0 map_1:  0  map_2:  0\n",
      "173  l= 0 map_1:  0  map_2:  0\n",
      "174  l= 0 map_1:  0  map_2:  0\n",
      "175  l= 0 map_1:  0  map_2:  0\n",
      "176  l= 0 map_1:  0  map_2:  0\n",
      "177  l= 1 map_1:  0.142857142857  map_2:  0.25\n",
      "178  l= 0 map_1:  0  map_2:  0\n",
      "179  l= 0 map_1:  0  map_2:  0\n",
      "180  l= 0 map_1:  0  map_2:  0\n",
      "181  l= 0 map_1:  0  map_2:  0\n",
      "182  l= 0 map_1:  0  map_2:  0\n"
     ]
    }
   ],
   "source": [
    "from QAData import QAPair\n",
    "\n",
    "first_map = []\n",
    "second_map = []\n",
    "final_1_predictions = []\n",
    "final_2_predictions = []\n",
    "ids_q = []\n",
    "for key,group in groupby(qa_pair['test'], lambda x: x.qi):\n",
    "    first_qapair = []\n",
    "    for qp in group:\n",
    "        first_qapair.append(qp)\n",
    "    # Get first predictions without rerank\n",
    "    first_qxa, first_l = k_model.buildCosineSimMatrix(first_qapair, max_terms=k_model.max_words)\n",
    "    first_predictions = model.predict(np.array(first_qxa))\n",
    "    first_map.append(avg_precision(first_l, first_predictions))\n",
    "    final_1_predictions.extend(first_predictions)\n",
    "    # Get second preditions taking into account the pseudo relevance feedback\n",
    "    maxq = np.argmax(first_predictions)\n",
    "    #q_1 = ' '.join([word for word in first_qapair[maxq].q.split() if word not in (stopwords.words('english'))])\n",
    "    a_1 = ' '.join([word for word in first_qapair[maxq].a.split() if word not in (stopwords.words('english'))])\n",
    "    q = ' '.join([word for word in qp.q.split() if word not in (stopwords.words('english'))])\n",
    "    second_qapair = [ QAPair(qp.qi, q+' '+a_1,qp.ai,qp.a,qp.l) for qp in first_qapair ]\n",
    "    second_qxa, second_l = k_model.buildCosineSimMatrix(second_qapair, max_terms=k_model.max_words)\n",
    "    second_predictions = model.predict(np.array(second_qxa))\n",
    "    second_predictions[maxq] = 1.0\n",
    "    second_map.append(avg_precision(second_l, second_predictions))\n",
    "    final_2_predictions.extend(second_predictions)\n",
    "    print first_qapair[0].qi, ' l=',sum(first_l), 'map_1: ', first_map[len(first_map)-1] ,' map_2: ', second_map[len(second_map)-1]\n",
    "    #print first_map, second_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.644079734044\n"
     ]
    }
   ],
   "source": [
    "print sum(first_map)/len(first_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.669580894184\n"
     ]
    }
   ],
   "source": [
    "print sum(second_map)/len(second_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rank_file_1 = 'experiments/rankfile_1.rank'\n",
    "idx_pred = 0\n",
    "rank_text = ''\n",
    "for key,group in groupby(qa_pair['test'], lambda x: x.qi):\n",
    "    for i, qp in enumerate(group):\n",
    "        rank_text += str(qp.qi) + ' 0 ' + str(qp.ai) + ' 0 ' + str(final_2_predictions[idx_pred][0]) + ' 0\\n'\n",
    "        idx_pred += 1\n",
    "with open(rank_file_1, 'wb') as text_file:\n",
    "    text_file.write(rank_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trec_eval: No queries with both results and relevance info\r\n"
     ]
    }
   ],
   "source": [
    "!/home/aerossom/trec_eval.9.0/trec_eval -c /home/aerossom/datasets/WikiQACorpus/WikiQA-test-filtered.ref \\\n",
    "experiments/rankfile_1.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runid                 \tall\t0\r\n",
      "num_q                 \tall\t95\r\n",
      "num_ret               \tall\t1517\r\n",
      "num_rel               \tall\t284\r\n",
      "num_rel_ret           \tall\t284\r\n",
      "map                   \tall\t0.6696\r\n",
      "gm_map                \tall\t0.3002\r\n",
      "Rprec                 \tall\t0.5847\r\n",
      "bpref                 \tall\t0.5833\r\n",
      "recip_rank            \tall\t0.7004\r\n",
      "iprec_at_recall_0.00  \tall\t0.7276\r\n",
      "iprec_at_recall_0.10  \tall\t0.7276\r\n",
      "iprec_at_recall_0.20  \tall\t0.7136\r\n",
      "iprec_at_recall_0.30  \tall\t0.7091\r\n",
      "iprec_at_recall_0.40  \tall\t0.6982\r\n",
      "iprec_at_recall_0.50  \tall\t0.6932\r\n",
      "iprec_at_recall_0.60  \tall\t0.6824\r\n",
      "iprec_at_recall_0.70  \tall\t0.6748\r\n",
      "iprec_at_recall_0.80  \tall\t0.6380\r\n",
      "iprec_at_recall_0.90  \tall\t0.6339\r\n",
      "iprec_at_recall_1.00  \tall\t0.6309\r\n",
      "P_5                   \tall\t0.3684\r\n",
      "P_10                  \tall\t0.2411\r\n",
      "P_15                  \tall\t0.1768\r\n",
      "P_20                  \tall\t0.1358\r\n",
      "P_30                  \tall\t0.0958\r\n",
      "P_100                 \tall\t0.0299\r\n",
      "P_200                 \tall\t0.0149\r\n",
      "P_500                 \tall\t0.0060\r\n",
      "P_1000                \tall\t0.0030\r\n"
     ]
    }
   ],
   "source": [
    "!/home/aerossom/trec_eval.9.0/trec_eval -c /home/aerossom/passage-retrieval/experiments/gold-jakana-test.rank experiments/rankfile_1.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-f47bb974a617>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Print learning history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# Print learning history\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAP': [0.50040411122804629, 0.52189223593768197, 0.55762187871781732],\n",
       " 'MRR': [0.5037535065417272, 0.5279446569060693, 0.5645427026029268],\n",
       " 'acc': [0.4765625, 0.4921875, 0.54296875],\n",
       " 'loss': [0.25362694263458252, 0.25330552458763123, 0.24734991788864136],\n",
       " 'val_acc': [0.5, 0.515625, 0.484375],\n",
       " 'val_loss': [0.25115877389907837, 0.24868617951869965, 0.24784004688262939]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('out_file', 'wb') as output:\n",
    "    pickle.dump(history.history, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 ARM",
   "language": "python",
   "name": "py2-arm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
