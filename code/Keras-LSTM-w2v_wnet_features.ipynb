{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 5103)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import wikiqahelper\n",
    "import wordrepresentation\n",
    "import data_stats\n",
    "from wikiqahelper import load_questions_from_file\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from gensim.utils import tokenize\n",
    "import numpy as np\n",
    "from keras.engine import Input\n",
    "from keras.layers import LSTM, SimpleRNN, GRU, Dense, Dropout, Activation, Embedding, Input, merge\n",
    "from keras.models import Model, Sequential\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import wordnet as wn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import logging\n",
    "from scipy import spatial\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#name used to generate treceval file and checkpoint\n",
    "filename = 'Keras-LSTM-w2v_wnet_features.rank'\n",
    "weights  = 'weights-best-kmf.hdf5'\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_w2v():\n",
    "    _fname = \"GoogleNews-vectors-negative300.bin\"\n",
    "    w2vModel = Doc2Vec.load_word2vec_format(_fname, binary=True)\n",
    "    return w2vModel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2v = load_w2v()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def word2vectSimilarity(list1, list2, w2v_model):\n",
    "    sum_list1 = np.zeros(300)\n",
    "    sum_list2 = np.zeros(300)\n",
    "    mult_vector = np.ones(300)\n",
    "    for wq in list1:\n",
    "        try:\n",
    "            sum_list1 += w2v_model[wq]\n",
    "        except Exception as e:\n",
    "            logger.debug(\"Word not in word2vect vocabulary \"+wq)\n",
    "    for aq in list2: \n",
    "        try:\n",
    "            sum_list2 += w2v_model[aq]\n",
    "        except Exception as e:\n",
    "            logger.debug(\"Word not in word2vect vocabulary \"+aq)\n",
    "    #print len(sum_list1), len(sum_list2)\n",
    "    #result = spatial.distance.cosine(sum_list1, sum_list2)\n",
    "    #result = np.multiply(sum_list1, sum_list2)\n",
    "    #result = np.concatenate((sum_list1, sum_list2, np.multiply(sum_list1, sum_list2)))\n",
    "    result = np.concatenate((sum_list1, sum_list2))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print word2vectSimilarity(['sky','dog','window', 'material'],['the','car','is', 'red'],w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildQAPairs(dataset):\n",
    "    #Construct Question Answer Pairs\n",
    "    questions_answer_pairs = []\n",
    "\n",
    "    for k, test_q_k in enumerate(dataset):\n",
    "        q = test_q_k.question\n",
    "        for i, a_i in enumerate(test_q_k.answers):\n",
    "            is_correct = 1 if i in test_q_k.correct_answer else 0\n",
    "            questions_answer_pairs += [(q, a_i, is_correct)]\n",
    "    return questions_answer_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepoSentence(s):\n",
    "    terms = tokenize(s)\n",
    "    terms = [word for word in terms ]#if word not in STOPWORDS]\n",
    "    return terms\n",
    "    \n",
    "def getWord2Vect(qaPair, MAX_WORDS=50):\n",
    "    question = prepoSentence(qaPair[0])\n",
    "    answer = prepoSentence(qaPair[1])\n",
    "    q_vect = []\n",
    "    a_vect = []\n",
    "    for i in range(MAX_WORDS):\n",
    "        q_vect.append(w2v[question[i]] if len(question)>i and question[i] in w2v else np.zeros(300))\n",
    "        a_vect.append(w2v[answer[i]] if len(answer)>i and answer[i] in w2v else np.zeros(300))\n",
    "    #label = [1,0] if qaPair[2] == 1 else [0,1]\n",
    "    label = qaPair[2]\n",
    "    return q_vect, a_vect, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Construct Training dataset \n",
    "questions = {}\n",
    "questions['train'], vocabulary, idf = load_questions_from_file('train', -1)\n",
    "questions['validate'], vocabulary, idf = load_questions_from_file('validate', -1)\n",
    "questions['test'], vocabulary, idf = load_questions_from_file('test', -1)\n",
    "#Get train qa pairs\n",
    "train_questions_answer_pairs = buildQAPairs(questions['train'])\n",
    "test_questions_answer_pairs = buildQAPairs(questions['test'])\n",
    "validate_questions_answer_pairs = buildQAPairs(questions['validate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n"
     ]
    }
   ],
   "source": [
    "print sum([1 for qa in validate_questions_answer_pairs if qa[2]==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2576\n"
     ]
    }
   ],
   "source": [
    "print sum([1 for qa in validate_questions_answer_pairs if qa[2]==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2117"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(questions['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'how are glacier caves formed ?',\n",
       " u'A partly submerged glacier cave on Perito Moreno Glacier .',\n",
       " 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_questions_answer_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor i, p in enumerate(train_questions_answer_pairs):\\n    #p = train_questions_answer_pairs[500]\\n    r = word2vectSimilarity(prepoSentence(p[0]),prepoSentence(p[1]),w2v)\\n    print i, ' ---> ',r,p[2]\\n\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for i, p in enumerate(train_questions_answer_pairs):\n",
    "    #p = train_questions_answer_pairs[500]\n",
    "    r = word2vectSimilarity(prepoSentence(p[0]),prepoSentence(p[1]),w2v)\n",
    "    print i, ' ---> ',r,p[2]\n",
    "'''\n",
    "#train_questions_answer_pairs[1033]\n",
    "#print word2vectSimilarity(prepoSentence(pair[0]),prepoSentence(pair[0]),w2v)\n",
    "#print word2vectSimilarity(['bicycle'],['bike'],w2v)\n",
    "#pair\n",
    "#print set(prepoSentence(pair[0])) | set(prepoSentence(pair[1])) \n",
    "#len(set(list1) | set(list2))< (len(set(list1))+len(set(list2))):\n",
    "#print word2vectSimilarity(prepoSentence(p[0]),prepoSentence(p[1]),w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load w2vect - wnet features\n",
    "train_questions_answer_pairs = [ (list(pair),word2vectSimilarity(prepoSentence(pair[0]),prepoSentence(pair[1]),w2v)) \\\n",
    "                            for i, pair in enumerate(train_questions_answer_pairs) ]\n",
    "test_questions_answer_pairs = [ (list(pair),word2vectSimilarity(prepoSentence(pair[0]),prepoSentence(pair[1]),w2v)) \\\n",
    "                            for i, pair in enumerate(test_questions_answer_pairs) ]\n",
    "validate_questions_answer_pairs = [ (list(pair),word2vectSimilarity(prepoSentence(pair[0]),prepoSentence(pair[1]),w2v)) \\\n",
    "                            for i, pair in enumerate(validate_questions_answer_pairs) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_questions_answer_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q_bins = [ len(prepoSentence(t_qa[0][0])) for t_qa in train_questions_answer_pairs ]\n",
    "a_bins = [ len(prepoSentence(t_qa[0][1])) for t_qa in train_questions_answer_pairs ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhQAAAFkCAYAAAB4sKK5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2jwMuXbvT18AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f45d8317d50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bins = np.linspace(0, 50, 100)\n",
    "plt.hist(q_bins, bins, alpha=0.5, label='Question lenght (train)')\n",
    "plt.hist(a_bins, bins, alpha=0.5, label='Answer lenght (train)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generateXYBatches(validation=False, samples=2200, MAX_WORDS=50):\n",
    "    half_samples = samples/2\n",
    "    positiveSamples = [ q for q in train_questions_answer_pairs if q[0][2]==1 ]\n",
    "    negativeSamples = [ q for q in train_questions_answer_pairs if q[0][2]==0 ]\n",
    "    if validation:\n",
    "        positiveSamples = [ q for q in validate_questions_answer_pairs if q[0][2]==1 ]\n",
    "        negativeSamples = [ q for q in validate_questions_answer_pairs if q[0][2]==0 ]\n",
    "    while 1:\n",
    "        train_X1 = []\n",
    "        train_X2 = []\n",
    "        train_X3 = []\n",
    "        train_Y = []\n",
    "        rand_vector_pos = np.random.randint(0,len(positiveSamples),size=half_samples)\n",
    "        rand_vector_neg = np.random.randint(0,len(negativeSamples),size=half_samples)\n",
    "        X_pos = [ positiveSamples[i] for i in range(len(positiveSamples)) if i in rand_vector_pos]\n",
    "        X_neg = [ negativeSamples[i] for i in range(len(negativeSamples)) if i in rand_vector_neg]\n",
    "        for qa_pair in X_pos:\n",
    "            q_vect, a_vect, label = getWord2Vect(qa_pair[0], MAX_WORDS)\n",
    "            train_X1.append(q_vect)\n",
    "            train_X2.append(a_vect)\n",
    "            train_X3.append(qa_pair[1])\n",
    "            train_Y.append(label)\n",
    "        for qa_pair in X_neg:\n",
    "            q_vect, a_vect, label = getWord2Vect(qa_pair[0], MAX_WORDS)\n",
    "            train_X1.append(q_vect)\n",
    "            train_X2.append(a_vect)\n",
    "            train_X3.append(qa_pair[1])\n",
    "            train_Y.append(label)\n",
    "        train_X1 = np.array(train_X1)\n",
    "        train_X2 = np.array(train_X2)\n",
    "        train_X3 = np.array(train_X3)\n",
    "        #train_X  = np.sum([train_X1,train_X2],axis=0)\n",
    "        train_Y = np.array(train_Y)\n",
    "        #X = X_pos + X_neg\n",
    "        #train_q, train_a, train_l = wikiqa_model.buildWord2VectMatrix(X)\n",
    "        #q_vect, a_vect, label = getWord2Vect(qa_pair)\n",
    "        print \"   Samples generated = \", len(train_X1), '  -  Validation(',validation, ')'\n",
    "        #yield (train_X, train_Y)\n",
    "        yield ([train_X1, train_X2, train_X3], train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-23-f64a6dd81de2>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-23-f64a6dd81de2>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    print 'MAP = 'y_true, y_pred\u001b[0m\n\u001b[0m                       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def mean_avg_prec(y_true, y_pred):\n",
    "    print 'MAP = ', y_true, y_pred\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "\"\"\"\n",
    "Precision is the count of RELEVANT documents in the answer set \n",
    "divided by the count of documents in the answer set \n",
    "indicating the proportion of retrieved documents which are relevant\n",
    "Precision = ∣RelRetrieved∣ / ∣Retrieved∣\n",
    "\"\"\"\n",
    "def m_precision(y_true, y_pred):\n",
    "    print 'MAP = ', y_true, y_pred\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "\"\"\"\n",
    "Recall is the count of relevant documents in the answer set \n",
    "divided by the count of relevant documents in the corpus \n",
    "showing the proportion of relevant documents which have been retrieved\n",
    "Recall = ∣RelRetrieved∣ / ∣Rel in Collection∣\n",
    "\"\"\"\n",
    "def m_recall(y_true, y_pred):\n",
    "    print 'MAP = ', y_true, y_pred\n",
    "    return K.mean(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_1 (InputLayer)             (None, 50, 300)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input_2 (InputLayer)             (None, 50, 300)       0                                            \n",
      "____________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                    (None, 64)            93440       input_1[0][0]                    \n",
      "                                                                   input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "merge_1 (Merge)                  (None, 128)           0           lstm_1[0][0]                     \n",
      "                                                                   lstm_1[1][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "input_3 (InputLayer)             (None, 600)           0                                            \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 32)            4128        merge_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 32)            19232       input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "merge_2 (Merge)                  (None, 64)            0           dense_1[0][0]                    \n",
      "                                                                   dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 64)            4160        merge_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 64)            0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 32)            2080        dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_5 (Dense)                  (None, 1)             33          dense_4[0][0]                    \n",
      "====================================================================================================\n",
      "Total params: 123073\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "timesteps = 50\n",
    "question_input = Input(shape=(timesteps, 300))\n",
    "answer_input = Input(shape=(timesteps, 300))\n",
    "w2v_cos_distance = Input(shape=(600,))\n",
    "shared_lstm = LSTM(64)\n",
    "encoded_q = shared_lstm(question_input)\n",
    "encoded_a = shared_lstm(answer_input)\n",
    "merged_vector = merge([encoded_q, encoded_a], mode='concat', concat_axis=-1)\n",
    "sim = Dense(32, activation='sigmoid')(merged_vector)\n",
    "sim_w2v = Dense(32, activation='sigmoid')(w2v_cos_distance)\n",
    "merged_vector_2 = merge([sim, sim_w2v], mode='concat', concat_axis=-1)\n",
    "sim2 = Dense(64, activation='sigmoid')(merged_vector_2)\n",
    "drop = Dropout(0.2)(sim2)\n",
    "sim3 = Dense(32, activation='sigmoid')(drop)\n",
    "predictions = Dense(1, activation='sigmoid')(sim3)\n",
    "\n",
    "# If it is necessary to load the best pretrained weights\n",
    "# model.load_weights(\"check-points/\"+filename+\"-weights-best.hdf5\")\n",
    "\n",
    "model = Model(input=[question_input, answer_input,w2v_cos_distance], output=predictions)\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss=\"binary_crossentropy\",# kullback_leibler_divergence mean_squared_error\n",
    "              metrics=['accuracy', mean_avg_prec])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"638pt\" viewBox=\"0.00 0.00 352.00 638.00\" width=\"352pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 634)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-634 348,-634 348,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 139931312821136 -->\n",
       "<g class=\"node\" id=\"node1\"><title>139931312821136</title>\n",
       "<polygon fill=\"none\" points=\"-0.5,-593 -0.5,-629 130.5,-629 130.5,-593 -0.5,-593\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"65\" y=\"-607.3\">input_1 (InputLayer)</text>\n",
       "</g>\n",
       "<!-- 139931310406544 -->\n",
       "<g class=\"node\" id=\"node3\"><title>139931310406544</title>\n",
       "<polygon fill=\"none\" points=\"87,-519 87,-555 191,-555 191,-519 87,-519\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-533.3\">lstm_1 (LSTM)</text>\n",
       "</g>\n",
       "<!-- 139931312821136&#45;&gt;139931310406544 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>139931312821136-&gt;139931310406544</title>\n",
       "<path d=\"M82.537,-592.937C91.9604,-583.768 103.739,-572.308 114.096,-562.231\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"116.606,-564.672 121.332,-555.19 111.724,-559.655 116.606,-564.672\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139931312986192 -->\n",
       "<g class=\"node\" id=\"node2\"><title>139931312986192</title>\n",
       "<polygon fill=\"none\" points=\"148.5,-593 148.5,-629 279.5,-629 279.5,-593 148.5,-593\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"214\" y=\"-607.3\">input_2 (InputLayer)</text>\n",
       "</g>\n",
       "<!-- 139931312986192&#45;&gt;139931310406544 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>139931312986192-&gt;139931310406544</title>\n",
       "<path d=\"M196.226,-592.937C186.675,-583.768 174.738,-572.308 164.241,-562.231\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"166.544,-559.591 156.906,-555.19 161.696,-564.64 166.544,-559.591\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139931277358288 -->\n",
       "<g class=\"node\" id=\"node4\"><title>139931277358288</title>\n",
       "<polygon fill=\"none\" points=\"82.5,-445 82.5,-481 195.5,-481 195.5,-445 82.5,-445\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"139\" y=\"-459.3\">merge_1 (Merge)</text>\n",
       "</g>\n",
       "<!-- 139931310406544&#45;&gt;139931277358288 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>139931310406544-&gt;139931277358288</title>\n",
       "<path d=\"M139,-518.937C139,-510.807 139,-500.876 139,-491.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"142.5,-491.441 139,-481.441 135.5,-491.441 142.5,-491.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139931276417168 -->\n",
       "<g class=\"node\" id=\"node6\"><title>139931276417168</title>\n",
       "<polygon fill=\"none\" points=\"92.5,-371 92.5,-407 199.5,-407 199.5,-371 92.5,-371\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"146\" y=\"-385.3\">dense_1 (Dense)</text>\n",
       "</g>\n",
       "<!-- 139931277358288&#45;&gt;139931276417168 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>139931277358288-&gt;139931276417168</title>\n",
       "<path d=\"M140.659,-444.937C141.458,-436.719 142.436,-426.66 143.336,-417.406\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"146.82,-417.732 144.304,-407.441 139.853,-417.055 146.82,-417.732\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139931310406224 -->\n",
       "<g class=\"node\" id=\"node5\"><title>139931310406224</title>\n",
       "<polygon fill=\"none\" points=\"213.5,-445 213.5,-481 344.5,-481 344.5,-445 213.5,-445\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"279\" y=\"-459.3\">input_3 (InputLayer)</text>\n",
       "</g>\n",
       "<!-- 139931276417616 -->\n",
       "<g class=\"node\" id=\"node7\"><title>139931276417616</title>\n",
       "<polygon fill=\"none\" points=\"221.5,-371 221.5,-407 328.5,-407 328.5,-371 221.5,-371\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"275\" y=\"-385.3\">dense_2 (Dense)</text>\n",
       "</g>\n",
       "<!-- 139931310406224&#45;&gt;139931276417616 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>139931310406224-&gt;139931276417616</title>\n",
       "<path d=\"M278.052,-444.937C277.6,-436.807 277.049,-426.876 276.539,-417.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"280.018,-417.231 275.969,-407.441 273.029,-417.619 280.018,-417.231\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139931276495696 -->\n",
       "<g class=\"node\" id=\"node8\"><title>139931276495696</title>\n",
       "<polygon fill=\"none\" points=\"153.5,-297 153.5,-333 266.5,-333 266.5,-297 153.5,-297\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210\" y=\"-311.3\">merge_2 (Merge)</text>\n",
       "</g>\n",
       "<!-- 139931276417168&#45;&gt;139931276495696 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>139931276417168-&gt;139931276495696</title>\n",
       "<path d=\"M161.167,-370.937C169.101,-362.012 178.964,-350.916 187.745,-341.037\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"190.469,-343.24 194.497,-333.441 185.238,-338.59 190.469,-343.24\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139931276417616&#45;&gt;139931276495696 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>139931276417616-&gt;139931276495696</title>\n",
       "<path d=\"M259.596,-370.937C251.539,-362.012 241.521,-350.916 232.603,-341.037\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"235.044,-338.518 225.745,-333.441 229.848,-343.209 235.044,-338.518\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139931276512464 -->\n",
       "<g class=\"node\" id=\"node9\"><title>139931276512464</title>\n",
       "<polygon fill=\"none\" points=\"156.5,-223 156.5,-259 263.5,-259 263.5,-223 156.5,-223\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210\" y=\"-237.3\">dense_3 (Dense)</text>\n",
       "</g>\n",
       "<!-- 139931276495696&#45;&gt;139931276512464 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>139931276495696-&gt;139931276512464</title>\n",
       "<path d=\"M210,-296.937C210,-288.807 210,-278.876 210,-269.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"213.5,-269.441 210,-259.441 206.5,-269.441 213.5,-269.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139931276512912 -->\n",
       "<g class=\"node\" id=\"node10\"><title>139931276512912</title>\n",
       "<polygon fill=\"none\" points=\"145,-149 145,-185 275,-185 275,-149 145,-149\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210\" y=\"-163.3\">dropout_1 (Dropout)</text>\n",
       "</g>\n",
       "<!-- 139931276512464&#45;&gt;139931276512912 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>139931276512464-&gt;139931276512912</title>\n",
       "<path d=\"M210,-222.937C210,-214.807 210,-204.876 210,-195.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"213.5,-195.441 210,-185.441 206.5,-195.441 213.5,-195.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139931276415696 -->\n",
       "<g class=\"node\" id=\"node11\"><title>139931276415696</title>\n",
       "<polygon fill=\"none\" points=\"156.5,-75 156.5,-111 263.5,-111 263.5,-75 156.5,-75\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210\" y=\"-89.3\">dense_4 (Dense)</text>\n",
       "</g>\n",
       "<!-- 139931276512912&#45;&gt;139931276415696 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>139931276512912-&gt;139931276415696</title>\n",
       "<path d=\"M210,-148.937C210,-140.807 210,-130.876 210,-121.705\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"213.5,-121.441 210,-111.441 206.5,-121.441 213.5,-121.441\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 139931277116560 -->\n",
       "<g class=\"node\" id=\"node12\"><title>139931277116560</title>\n",
       "<polygon fill=\"none\" points=\"156.5,-1 156.5,-37 263.5,-37 263.5,-1 156.5,-1\" stroke=\"black\"/>\n",
       "<text font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"210\" y=\"-15.3\">dense_5 (Dense)</text>\n",
       "</g>\n",
       "<!-- 139931276415696&#45;&gt;139931277116560 -->\n",
       "<g class=\"edge\" id=\"edge12\"><title>139931276415696-&gt;139931277116560</title>\n",
       "<path d=\"M210,-74.937C210,-66.8072 210,-56.8761 210,-47.7047\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"213.5,-47.4406 210,-37.4407 206.5,-47.4407 213.5,-47.4406\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.visualize_util import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# checkpoints\n",
    "filepath=\"check-points/\"+filename+\"-\"+weights\n",
    "#output the model weights each time an improvement is observed during training\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "#stops if the model is not learning at any point\n",
    "earlyStopping=EarlyStopping(monitor='accuracy', patience=50, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "   Samples generated =  1763   -  Validation( False )\n",
      "1763/2000 [=========================>....] - ETA: 0s - loss: 0.6690 - acc: 0.6132 - mean_avg_prec: 0.3743   Samples generated =  1751   -  Validation( False )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aerossom/.conda/envs/py2/lib/python2.7/site-packages/keras/engine/training.py:1462: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Samples generated =  356   -  Validation( True )\n",
      "   Samples generated =  359   -  Validation( True )\n",
      "Epoch 00000: val_acc improved from -inf to 0.66993, saving model to check-points/Keras-LSTM-w2v_wnet_features.rank-weights-best-kmf.hdf5\n",
      "3514/2000 [====================================================] - 10s - loss: 0.6712 - acc: 0.6116 - mean_avg_prec: 0.4088 - val_loss: 0.6377 - val_acc: 0.6699 - val_mean_avg_prec: 0.3735"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aerossom/.conda/envs/py2/lib/python2.7/site-packages/keras/callbacks.py:358: RuntimeWarning: Early stopping requires accuracy available!\n",
      "  (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/500\n",
      "   Samples generated =  350   -  Validation( True )\n",
      "   Samples generated =  1773   -  Validation( False )\n",
      "1773/2000 [=========================>....] - ETA: 0s - loss: 0.6685 - acc: 0.6063 - mean_avg_prec: 0.3730   Samples generated =  1719   -  Validation( False )\n",
      "   Samples generated =  355   -  Validation( True )\n",
      "   Samples generated =  350   -  Validation( True )\n",
      "Epoch 00001: val_acc improved from 0.66993 to 0.67943, saving model to check-points/Keras-LSTM-w2v_wnet_features.rank-weights-best-kmf.hdf5\n",
      "3492/2000 [====================================================] - 7s - loss: 0.6669 - acc: 0.6137 - mean_avg_prec: 0.3865 - val_loss: 0.6325 - val_acc: 0.6794 - val_mean_avg_prec: 0.3739\n",
      "Epoch 3/500\n",
      "   Samples generated =  1763   -  Validation( False )\n",
      "   Samples generated =  351   -  Validation( True )\n",
      "1763/2000 [=========================>....] - ETA: 0s - loss: 0.6730 - acc: 0.6058 - mean_avg_prec: 0.3742   Samples generated =  1752   -  Validation( False )\n",
      "   Samples generated =  353   -  Validation( True )\n",
      "   Samples generated =  354   -  Validation( True )\n",
      "Epoch 00002: val_acc did not improve\n",
      "3515/2000 [====================================================] - 7s - loss: 0.6711 - acc: 0.6060 - mean_avg_prec: 0.3865 - val_loss: 0.6421 - val_acc: 0.6648 - val_mean_avg_prec: 0.3909\n",
      "Epoch 4/500\n",
      "   Samples generated =  1744   -  Validation( False )\n",
      "   Samples generated =  352   -  Validation( True )\n",
      "1744/2000 [=========================>....] - ETA: 0s - loss: 0.6639 - acc: 0.6175 - mean_avg_prec: 0.3910   Samples generated =  1732   -  Validation( False )\n",
      "   Samples generated =  354   -  Validation( True )\n",
      "   Samples generated =  353   -  Validation( True )\n",
      "Epoch 00003: val_acc did not improve\n",
      "3476/2000 [====================================================] - 6s - loss: 0.6646 - acc: 0.6165 - mean_avg_prec: 0.3877 - val_loss: 0.6376 - val_acc: 0.6662 - val_mean_avg_prec: 0.3806\n",
      "Epoch 5/500\n",
      "   Samples generated =  1731   -  Validation( False )\n",
      "   Samples generated =  343   -  Validation( True )\n",
      "1731/2000 [========================>.....] - ETA: 0s - loss: 0.6638 - acc: 0.6158 - mean_avg_prec: 0.3821   Samples generated =  1766   -  Validation( False )\n",
      "   Samples generated =  352   -  Validation( True )\n",
      "   Samples generated =  1752   -  Validation( False )\n",
      "   Samples generated =  355   -  Validation( True )\n",
      "Epoch 00004: val_acc did not improve\n",
      "3497/2000 [====================================================] - 7s - loss: 0.6628 - acc: 0.6140 - mean_avg_prec: 0.3848 - val_loss: 0.6312 - val_acc: 0.6775 - val_mean_avg_prec: 0.3839\n",
      "Epoch 6/500\n",
      "   Samples generated =  351   -  Validation( True )\n",
      "1752/2000 [=========================>....] - ETA: 0s - loss: 0.6621 - acc: 0.6102 - mean_avg_prec: 0.3845   Samples generated =  1737   -  Validation( False )\n",
      "   Samples generated =  350   -  Validation( True )\n",
      "   Samples generated =  354   -  Validation( True )\n",
      "   Samples generated =  1745   -  Validation( False )\n",
      "Epoch 00005: val_acc did not improve\n",
      "3489/2000 [====================================================] - 6s - loss: 0.6613 - acc: 0.6128 - mean_avg_prec: 0.3939 - val_loss: 0.6269 - val_acc: 0.6733 - val_mean_avg_prec: 0.3629\n",
      "Epoch 7/500\n",
      "   Samples generated =  348   -  Validation( True )\n",
      "1745/2000 [=========================>....] - ETA: 0s - loss: 0.6620 - acc: 0.6103 - mean_avg_prec: 0.3643   Samples generated =  1745   -  Validation( False )\n",
      "   Samples generated =  348   -  Validation( True )\n",
      "   Samples generated =  357   -  Validation( True )\n",
      "Epoch 00006: val_acc did not improve\n",
      "3490/2000 [====================================================] - 6s - loss: 0.6601 - acc: 0.6106 - mean_avg_prec: 0.3843 - val_loss: 0.6291 - val_acc: 0.6681 - val_mean_avg_prec: 0.3791\n",
      "Epoch 8/500\n",
      "   Samples generated =  1743   -  Validation( False )\n",
      "   Samples generated =  356   -  Validation( True )\n",
      "1743/2000 [=========================>....] - ETA: 0s - loss: 0.6574 - acc: 0.6110 - mean_avg_prec: 0.3817   Samples generated =  1729   -  Validation( False )\n",
      "   Samples generated =  351   -  Validation( True )\n",
      "   Samples generated =  359   -  Validation( True )\n",
      "Epoch 00007: val_acc did not improve\n",
      "3472/2000 [====================================================] - 6s - loss: 0.6544 - acc: 0.6164 - mean_avg_prec: 0.3892 - val_loss: 0.6206 - val_acc: 0.6704 - val_mean_avg_prec: 0.3659\n",
      "Epoch 9/500\n",
      "   Samples generated =  1764   -  Validation( False )\n",
      "   Samples generated =  357   -  Validation( True )\n",
      "1764/2000 [=========================>....] - ETA: 0s - loss: 0.6541 - acc: 0.6094 - mean_avg_prec: 0.3693   Samples generated =  1751   -  Validation( False )\n",
      "   Samples generated =  354   -  Validation( True )\n",
      "   Samples generated =  362   -  Validation( True )\n",
      "Epoch 00008: val_acc did not improve\n",
      "3515/2000 [====================================================] - 7s - loss: 0.6546 - acc: 0.6125 - mean_avg_prec: 0.3844 - val_loss: 0.6205 - val_acc: 0.6662 - val_mean_avg_prec: 0.3745\n",
      "Epoch 10/500\n",
      "   Samples generated =  1740   -  Validation( False )\n",
      "   Samples generated =  347   -  Validation( True )\n",
      "1740/2000 [=========================>....] - ETA: 0s - loss: 0.6473 - acc: 0.6161 - mean_avg_prec: 0.3783   Samples generated =  1738   -  Validation( False )\n",
      "   Samples generated =  1736   -  Validation( False )\n",
      "   Samples generated =  349   -  Validation( True )\n",
      "   Samples generated =  364   -  Validation( True )\n",
      "Epoch 00009: val_acc did not improve\n",
      "3478/2000 [====================================================] - 7s - loss: 0.6466 - acc: 0.6176 - mean_avg_prec: 0.3904 - val_loss: 0.6118 - val_acc: 0.6732 - val_mean_avg_prec: 0.3536\n",
      "Epoch 11/500\n",
      "   Samples generated =  360   -  Validation( True )\n",
      "1736/2000 [=========================>....] - ETA: 0s - loss: 0.6494 - acc: 0.6112 - mean_avg_prec: 0.3566   Samples generated =  1739   -  Validation( False )\n",
      "   Samples generated =  349   -  Validation( True )\n",
      "   Samples generated =  1773   -  Validation( False )\n",
      "   Samples generated =  352   -  Validation( True )\n",
      "Epoch 00010: val_acc did not improve\n",
      "3475/2000 [====================================================] - 5s - loss: 0.6490 - acc: 0.6158 - mean_avg_prec: 0.3903 - val_loss: 0.5998 - val_acc: 0.6776 - val_mean_avg_prec: 0.3522\n",
      "Epoch 12/500\n",
      "   Samples generated =  359   -  Validation( True )\n",
      "1773/2000 [=========================>....] - ETA: 0s - loss: 0.6458 - acc: 0.6091 - mean_avg_prec: 0.3618   Samples generated =  1729   -  Validation( False )\n",
      "   Samples generated =  364   -  Validation( True )\n",
      "   Samples generated =  358   -  Validation( True )\n",
      "Epoch 00011: val_acc did not improve\n",
      "3502/2000 [====================================================] - 6s - loss: 0.6420 - acc: 0.6222 - mean_avg_prec: 0.3875 - val_loss: 0.6075 - val_acc: 0.6634 - val_mean_avg_prec: 0.3561\n",
      "Epoch 13/500\n",
      "   Samples generated =  1756   -  Validation( False )\n",
      "   Samples generated =  356   -  Validation( True )\n",
      "1756/2000 [=========================>....] - ETA: 0s - loss: 0.6378 - acc: 0.6145 - mean_avg_prec: 0.3624   Samples generated =  1725   -  Validation( False )\n",
      "   Samples generated =  1759   -  Validation( False )\n",
      "   Samples generated =  353   -  Validation( True )\n",
      "   Samples generated =  355   -  Validation( True )\n",
      "Epoch 00012: val_acc did not improve\n",
      "3481/2000 [====================================================] - 7s - loss: 0.6366 - acc: 0.6271 - mean_avg_prec: 0.3883 - val_loss: 0.5980 - val_acc: 0.6709 - val_mean_avg_prec: 0.3467\n",
      "Epoch 14/500\n",
      "   Samples generated =  349   -  Validation( True )\n",
      "1759/2000 [=========================>....] - ETA: 0s - loss: 0.6341 - acc: 0.6174 - mean_avg_prec: 0.3512   Samples generated =  1746   -  Validation( False )\n",
      "   Samples generated =  357   -  Validation( True )\n",
      "   Samples generated =  351   -  Validation( True )\n",
      "Epoch 00013: val_acc improved from 0.67943 to 0.68362, saving model to check-points/Keras-LSTM-w2v_wnet_features.rank-weights-best-kmf.hdf5\n",
      "3505/2000 [====================================================] - 6s - loss: 0.6304 - acc: 0.6354 - mean_avg_prec: 0.3780 - val_loss: 0.5948 - val_acc: 0.6836 - val_mean_avg_prec: 0.3678\n",
      "Epoch 15/500\n",
      "   Samples generated =  1747   -  Validation( False )\n",
      "   Samples generated =  355   -  Validation( True )\n",
      "1747/2000 [=========================>....] - ETA: 0s - loss: 0.6218 - acc: 0.6365 - mean_avg_prec: 0.3739   Samples generated =  1758   -  Validation( False )\n",
      "   Samples generated =  348   -  Validation( True )\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-f64eca2535b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mepochs_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerateXYBatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_WORDS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerateXYBatches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_WORDS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimesteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m             \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mearlyStopping\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/aerossom/.conda/envs/py2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1469\u001b[0m                         val_outs = self.evaluate_generator(validation_data,\n\u001b[1;32m   1470\u001b[0m                                                            \u001b[0mnb_val_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1471\u001b[0;31m                                                            max_q_size=max_q_size)\n\u001b[0m\u001b[1;32m   1472\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1473\u001b[0m                         \u001b[0;31m# no need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aerossom/.conda/envs/py2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, val_samples, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[1;32m   1552\u001b[0m                                 'or (x, y). Found: ' + str(generator_output))\n\u001b[1;32m   1553\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1555\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m                 \u001b[0m_stop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aerossom/.conda/envs/py2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtest_on_batch\u001b[0;34m(self, x, y, sample_weight)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aerossom/.conda/envs/py2/lib/python2.7/site-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    715\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aerossom/.conda/envs/py2/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/aerossom/.conda/envs/py2/lib/python2.7/site-packages/theano/scan_module/scan_op.pyc\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    948\u001b[0m         \u001b[0mallow_gc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_gc\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_gc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[0m\u001b[1;32m    951\u001b[0m                  allow_gc=allow_gc):\n\u001b[1;32m    952\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs_number = 500\n",
    "history = model.fit_generator(generateXYBatches(validation=False, MAX_WORDS=timesteps), samples_per_epoch=2000, \\\n",
    "            validation_data=generateXYBatches(validation=True,samples=500, MAX_WORDS=timesteps), nb_val_samples=400, \\\n",
    "            nb_epoch=epochs_number, callbacks=[checkpoint, earlyStopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-d63b94348b32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Print learning history\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# summarize history for accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Print learning history\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "check-points/Keras-LSTM-w2v_wnet_features.rank-weights-best.hdf5\n"
     ]
    }
   ],
   "source": [
    "#reload best weights\n",
    "model.load_weights(\"check-points/\"+filename+\"-\"+weights)\n",
    "print \"check-points/\"+filename+\"-weights-best.hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6156, 50, 300) (6156,)\n"
     ]
    }
   ],
   "source": [
    "#Construct Test dataset \n",
    "test_X1 = []\n",
    "test_X2 = []\n",
    "test_X3 = []\n",
    "test_Y = []           \n",
    "\n",
    "for qa_pair in test_questions_answer_pairs:\n",
    "    q_vect, a_vect, label = getWord2Vect(qa_pair[0],MAX_WORDS=timesteps)\n",
    "    test_X1.append(q_vect)\n",
    "    test_X2.append(a_vect)\n",
    "    test_X3.append(qa_pair[1])\n",
    "    test_Y.append(label)\n",
    "    \n",
    "test_X1 = np.array(test_X1)\n",
    "test_X2 = np.array(test_X2)\n",
    "test_X3 = np.array(test_X3)\n",
    "test_Y = np.array(test_Y)\n",
    "\n",
    "print test_X1.shape, test_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6156/6156 [==============================] - 4s     \n",
      "Test loss / test accuracy = 0.1530 / 0.8093\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate([test_X1, test_X2, test_X3], test_Y, 50)\n",
    "#loss, acc = model.evaluate(test_X, test_Y, batch_size, show_accuracy=True)\n",
    "print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict([test_X1, test_X2, test_X3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1473.4375] [ 0.24401106] 293\n"
     ]
    }
   ],
   "source": [
    "print np.sum(predictions, axis=0), predictions[1234], np.sum(test_Y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1473.4375] [ 0.0528559] 293\n"
     ]
    }
   ],
   "source": [
    "print np.sum(predictions, axis=0), predictions[22], np.sum(test_Y, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genTrecEvalFile(result, filename):\n",
    "    idx_pred = 0\n",
    "    with open('experiments/'+filename, 'wb') as text_file:\n",
    "        for i, test_q_i in enumerate(questions['test']):\n",
    "            for j, a_j in enumerate(test_q_i.answers):\n",
    "                # 1 --> [1,0]\n",
    "                #label = 1 if (predictions[idx_pred][0]-0.06)>predictions[idx_pred][1] else 0\n",
    "                label = predictions[idx_pred][0]\n",
    "                str_out = str(i + 1) + ' 0 ' + str(j) + ' 0 ' + str(label) + ' 0\\n'\n",
    "                idx_pred += 1\n",
    "                text_file.write(str_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras-LSTM-w2v_wnet_features.rank\n"
     ]
    }
   ],
   "source": [
    "genTrecEvalFile(predictions, filename)\n",
    "print filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "runid                 \tall\t0\r\n",
      "num_q                 \tall\t237\r\n",
      "num_ret               \tall\t2341\r\n",
      "num_rel               \tall\t283\r\n",
      "num_rel_ret           \tall\t283\r\n",
      "map                   \tall\t0.5302\r\n",
      "gm_map                \tall\t0.4121\r\n",
      "Rprec                 \tall\t0.3277\r\n",
      "bpref                 \tall\t0.3267\r\n",
      "recip_rank            \tall\t0.5482\r\n",
      "iprec_at_recall_0.00  \tall\t0.5519\r\n",
      "iprec_at_recall_0.10  \tall\t0.5519\r\n",
      "iprec_at_recall_0.20  \tall\t0.5519\r\n",
      "iprec_at_recall_0.30  \tall\t0.5455\r\n",
      "iprec_at_recall_0.40  \tall\t0.5379\r\n",
      "iprec_at_recall_0.50  \tall\t0.5379\r\n",
      "iprec_at_recall_0.60  \tall\t0.5196\r\n",
      "iprec_at_recall_0.70  \tall\t0.5196\r\n",
      "iprec_at_recall_0.80  \tall\t0.5195\r\n",
      "iprec_at_recall_0.90  \tall\t0.5195\r\n",
      "iprec_at_recall_1.00  \tall\t0.5195\r\n",
      "P_5                   \tall\t0.1899\r\n",
      "P_10                  \tall\t0.1135\r\n",
      "P_15                  \tall\t0.0779\r\n",
      "P_20                  \tall\t0.0595\r\n",
      "P_30                  \tall\t0.0398\r\n",
      "P_100                 \tall\t0.0119\r\n",
      "P_200                 \tall\t0.0060\r\n",
      "P_500                 \tall\t0.0024\r\n",
      "P_1000                \tall\t0.0012\r\n"
     ]
    }
   ],
   "source": [
    "!/home/aerossom/trec_eval.9.0/trec_eval -c ../datasets/WikiQACorpus/WikiQA-test-filtered.ref experiments/Keras-LSTM-w2v_wnet_features.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!cat ../passage-retrieval/experiments/lstm-sum.rank "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: /home/aerossom/trec_eval-9.0/trec_eval: not found\r\n"
     ]
    }
   ],
   "source": [
    "!/home/aerossom/trec_eval-9.0/trec_eval -c ../passage-retrieval/experiments/gold-jakana-test.rank ../passage-retrieval/experiments/keras_lstm_1489277643.rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 ARM",
   "language": "python",
   "name": "py2-arm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
